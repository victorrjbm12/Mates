\chapter{Apunts d'integració convexa}
El que segueix són apunts del seminari \textit{Convex Integration, Staircase Laminates and Applications} d'en Daniel Faraco, de part de la Universitat Autònoma de Madrid, el dia 17 de març de 2025. BGSMATH2025.

\section{Dia 1}
La integració convexa comença amb l'article de Nash sobre les encabiments $C^1$. La pregunta era si pots posar una esfera de manera isomètrica en una esfera més petita. Fiques una varietat $2D$, l'esfera, en una esfera en $\mathbb R^3$. 

La condició \textbf{d'isometria} és que $Du^\intercal Du = g$. Nash comença amb una immersió curta i troba una d'isomètrica. 

Esculls adequadament les pertorbacions de la immersió i obtens el resultat, com ja sabem. El resultat no és particularment útil, potser, però el mètode concret que fa servir és el que anomenem \textbf{integració convexa}, que és molt útil. En general, si hi ha una sèrie de PDE i les dones a través del límit d'unes pertorbacions, donada una subsolució final. 
$$u^\infty = \lim_{N\to\infty} u^N,$$
on $u^{N+1} - u^N = \omega_q$ i $\omega_q$ té paràmetres d'oscil·lació i concentració $\lambda_q$ i $\tau_q$, amb direccions $\eta_k^1\eta_k^2$. i funcions oscil·lants $\phi$.

Considerarem que les aplicacions curtes són \textbf{límits febles}, on els límits febles tals que 
$$\not\int_E u_\gamma \to \not\int_E \overline u$$
FORMULA 1, són \textbf{course grain solutions}. Diu que en aplicacions a PDE, la solució seria \say{micro} i el límit feble seria \say{macro}.

Gromov és potser qui comença a desenvolupar aquest mètode de Nash. Altres van veure que això servia en dinàmica de fluids. 

\textbf{Laminats d'escala} són un mètode inventat pel Faraco per resoldre equacions el·líptiques isotròpiques. Es fan en tres passos:
\begin{itemize}
    \item[(1)] Escriure el problema com una inclusió diferencial: trobar un conjunt $K\subseteq M^{m\times n}$ tal que $u:\Omega\to\mathbb R^m$ i $Du(x)\in K$ a.e. $x\in\Omega$, on $K$ és un conjunt tancat euclidià que representa les dades del problema.
    \item[(2)] Aproximar la solució per $K$ per $$\int\text{dist}_K(Du)^p\le\varepsilon$$.
    \item[(3)] Combinar moltes solucions aproximades per construir una solució exacta.
\end{itemize}
Veurem aquí tota una sèrie d'aplicacions.

\subsubsection{Teoria de Calderón Zygmund}
Tenint en compte aquestes propietats i definició de la transformada de Fourier, FORMULA 2.

Per Plancherel, FORMULA 3, les derivades estan controlades per la laplaciana en la norma $L^2$. Però en $L^1$ això no és cert:
\begin{teo}\label{teo:primer}
    $\forall N,\Omega$ regular $\exists f_N$ amb $\int|\partial_{x1x2}f|\ge N$ i $\sup\set{|\partial_{x1x1}|,|\partial_{x2x2}|}\le 1$
\end{teo}

\subsubsection{Equacions el·líptiques i aplicacions quasiconformals}
En electrostàtica, si $u$ és el potencial elèctric, aleshores 
\begin{itemize}
    \item[--] $\text{div}(\rho\nabla u) = 0$ on $\rho$ la conductivitat.
    \item[--] Condició de frontera $u|_{\partial\Omega} = g$
    \item[--] Quan $\rho = 1$: $\text{div}(\nabla u) = \Delta u$
\end{itemize}
El·lipticitat quantitativa:
$$\frac1KI\le\rho(x)\le KI$$

La solució feble en forma distribucional és $$\int_\Omega\rho\nabla u \nabla \phi \text dx = 0,\quad,\forall\phi\in C_0^\infty(\Omega)$$
La manera d'arribar a això és amb la primera variació del funcional d'energia
$$I[u] = \int_\Omega\rho|\nabla u|^2\text dx$$
Però hem de veure quin és l'espai en què això té sentit. En general, necessitem $W^{1,2}(\Omega)$. La pregunta és si són solucions febles honestes. Hi ha qui les anomena solucions molt febles. 

I ara està parlant de coses del BIMR que no arribo a entendre. 

\section{Dia 2}
Mirarem C-Z en $L^1$, equacions el·líptiques, homeomorfismes patològics etc., on el que ens interessa és que els podem escriure $Df(x)\in E\subseteq M^{m\times n}$. 

El mètode que explicarà sera trobar $Df(x)\in E\subseteq M^{m\times n}$ tal que hi ha un exponent crític $p$ a $(J)$ tal que $Df\in L^{p,\infty}\subset\cap_{q<p}L^q\setminus L^p$.

Pel que fa a CZ ens interessa veure que no és vàlid en $L^1$. És a dir, que exiteis $u$ tal que $\int|\partial_{x1x2}u|=\infty$ però $|\partial_{x1x1}|+|\partial_{x2x2}|\le 1$.

Vam deduir l'operador estrella de Hodge, $\star$, per equacions el·líptiques. Les derivades conformes i anticonformes es poden escriure com coordenades complexes d'una matriu $2\times 2$. 

Si $A = \begin{pmatrix}a_{11}&a_{12}\\a_{21}&a_{22}\end{pmatrix} = (a_-,a_+)$, aleshores $\partial_{\overline z}f = \pm \kappa\overline{\partial_z}f$.
Escrivim $Df \in E_{\pm\kappa} = \set{a_-=\pm\kappa a_+}$. Si tenim una matriu conforme i diagonal, aleshores està en una diagonal. El que tenim ara és en dos plans, $a_-=-\kappa a_+$ i $a_-=\kappa a_+$. MIRAR DIBUIX.

\subsubsection{Beltrami no lineals}
$\partial_{\overline z}f = \mu\partial_z f$, ${\partial_{\overline z}f} = v\overline{\partial_z}f$, $\partial_{\overline z}f =\mu\partial_z f + v\overline{\partial_z}f$
es poden posar en una certa forma.



\section{Dia 3}
Recordem que el que volem, donat $u:\mathbb R^2\to\mathbb R^2$, descriure 
$$Du(x)\in K\quad\textrm{a.e. x}\quad (I)$$
Quina és la integrabilitat de $Du$? 
I volem reformular el problema com:
$$\exists g.d. v_u \text{ tal que } ...$$





\section{Dia 4}
Volem, com sempre, $Du\in K$ tal que $Du\in L^{p,\infty}\setminus L^p$ per algun $p$ crític.
Això és el mateix que fer una distribució de gradients tq el suport de $v_u\in K$, $v_u(x:|x|\ge t)\approx t^{-p}$.
Que serà el mateix que construir un laminat d'escala tal que $v_u\in\mathcal{SL}^p(K)$ 

Recordem que diem que $A$ i $B$ són rang 1 connectades si $A-B=a\otimes n$ tal que $\det(A-B)=0$. Per tant, $\forall 0\le\lambda\le1$, $\lambda s_A+(1-\lambda)s_B$ és (aprox) distribució de gradients.

Amb això podem trobar ua funció amb distribució de gradients només un en $A$ i un en $B$ (l'espai gradient vius a l'espai de les matrius, generat per $(1 0, 0 0)$ i $(0 0, 0 1)$ ) Aleshores les direccions de rang 1 són les horitzontals i verticals. El centre de masses d'una mesura generada (en horitzontal) per A i B està en el segment entre $A$ i $B$.

Les propietats que té la distribució de gradients per tal que funcionin és que siguin afins a trossos amb condicions afins de frontera, que ens fa més fàcil generar laminats. Si tenim $ABABAB$ haurem de posar a la frontera lateral una regió d'interpolació, i no hi ha problema canviant per exemple $B$ per $DEDEDE$ o alguna cosa així. Cada vegada que fem aquest procés, que la massa de $A$ es divideix entre $B$ i $C$ i la de $B$ entre $D$ i $E$, tenim una altra distribució gradient. 
Ara bé, amb això només podem fer coses amb matrius connectades rang 1. Ara bé, si no són connectades rang 1 això no funciona. El que hem construit fins ara eren prelaminats, els laminats són els límits de successions de prelaminats a mesura que fem més i més petites les cantonades.

La gran contribució de Tartar és que ser un camp gradient és només que el rotacional sigui 0. Anul·lar el rotacional és com resoldre un sistema d'equacions de primer ordre, per exemple $\mathcal L(z) = A_{ijk}\partial_j z^k$. Per cada operador diferencial existeix el que anomenem con d'ones $\Lambda_L$, el subconjunt de $\mathbb R^n$ tal que si $I\in\Lambda_L$ aleshores exiteix una direcció $\xi$ tal que per qualsevol $h:\mathbb R\to \mathbb R$ tenim que $\mathcal L(h)$ LHA TRET :(, que generalitza el concepte de connexió de rang 1.

Aquesta teoria no es restringeix només a gradients, sinó també a coses de Fraday blablabla.

Definició de laminat escala: tenim un conjunt $K\in M^{d\times m}$ on vull que es suporti, i $A\not\in K$. Aleshores l'esglaó $n$ serà $\omega_1=(1-\gamma_n)\mu_n+\gamma_n\delta_{A_n}$ i tal, de manera que anem pujant i suportant-nos on toca.











\newpage
\section{Apunts del paper de Nash del 1954}
{
\color{blue}
\begin{itemize}
    \item Parlar abans de la diferència entre el punt de vista extrínsec i intrínsec de la geometria, un cop haguem parlat de geodif. 
    \item Veurem que una varietat de dimensió $n$ es pot ficar en un espai $E^{2n}$, on aquí diem que $E^k$ és l'espai euclidià de dimensió $k$.
    \item Interessant que el procés de les correccions sempre augmenta les distàncies localment, motiu pel qual el primer ha de ser curt. Diu Nash que l'anem "estirant".
    \item Mirar el tema de si la caracterització de una immersió curta és diferent que a la que dona SJO.
    \item Si la varietat és tancada només cal canviar l'escala de $E^k$ per fer la immersió curta. Si és oberta cal fer una cosa més complicada.
    \item Coses a tenir en compte:
        \begin{itemize}
            \item $g_{ij}$ és la mètrica intrínseca, $h_{ij}$ és la mètrica induïda.
            \item $\set{x^i}$ són les coordenades en la varietat $M$.
            \item $\set{z^\alpha}$ són les coordenades en $E^k$.
            \item Amb la immersió, $z^\alpha = z^\alpha(x^1, \dots, x^n)$.
            \item La mètrica induïda és $h_{ij} = \frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\beta}{\partial x^j}$. Normalment estaria multiplicat per una $g_{\alpha\beta}$ que no apareix perquè en aquest cas és la mètrica euclidiana.
        \end{itemize}
    \item Cada correcció es va fent en infinites "etapes", cada una d'elles corregint la correcció de la etapa anterior. L'important aquí és que cada correcció manté el fet que la immersió sigui curta, tot i que cada vegada menys. Cada etapa ens hi hauria d'apropar la meitat del camí. Per exemple, després de la primera, l'error hauria de ser
    $$g_{ij}-\overline{h_{ij}}\approx \frac12(g_{ij}-h_{ij})$$
    \item Ho fem d'aquesta manera perquè així ens assegurem que cada correcció només ha d'augmentar la mètrica. 
    \item Cada etapa es divideix en passes (passos?), que afecten només localment la immersió augmentant la mètrica en una sola direcció. 
    \item Per tal de dividir en passos, dividim la varietat en una sèrie d'entorns amb $n$ paràmetres $C^\infty$ no singulars, i cada entorn es pot trobar amb un nombre finit d'altres entorns.
    \item Per cada un d'aquests entorns, per exemple $N_p$, prenem una funció $\varphi_p$ positiva a l'interior de $N_p$ i $0$ fora d'ell. Definim aquestes funcions tals que la suma de totes les $\varphi_p$ valgui $1$ en qualsevol punt. (Això com es fa? Diu que és estàndard però em sembla una mica complicat si ha de ser $C^\infty$.) Això serveix per distribuir la "càrrega" de la correcció.
    \item En cada entorn, la "càrrega" de la correcció es divideix també entre les passes. Sigui $\delta_{ij}=g_{ij}-h_{ij}$ l'error mètric després d'unes quantes etapes. A la propera voldríem augmentar la mètrica més o menys $\frac12\delta_{ij}$, de manera que a l'entorn $N_p$ voldríem augmentar la mètrica en $\frac12\varphi_p\delta_{ij}$. Per fer-ho haurem de trobar un tensor definit positiu $\beta_{ij}$ que sigui $C^\infty$ i aproximi $\delta_{ij}$.
    \item $$\frac12\varphi_p\beta_{ij} = \sum_{\nu}a_{\nu}\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}$$ on $x^i$ són coordenades de l'entorn $N_p$, $a_\nu$ funcions no-negatives $C^\infty$ i $\psi^\nu$ funcions lineals en $x^i$.
    \item A l'apartat \textbf{The normal fields}, diu que necessita dos camps vectorials unitaris $C^\infty$ normals a la immersió i ortogonals entre ells, $\zeta^\alpha$ i $\eta^\alpha$. Això és lo de la co-dimensió 2 que després Kuiper canvia a 1.
    \item La pertorbació associada a $a_\nu$ i $\psi^\nu$ és 
        \begin{equation}
            \boxed{\overline{z}^\alpha = z^\alpha + \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu) + \eta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\sin(\lambda \psi^\nu)}
        \end{equation}
        on $\lambda$ és un paràmetre que podem triar.
    \item El canvi mètric és $\sum_\alpha\frac{\partial\overline{z}^\alpha}{\partial x^i}\frac{\partial\overline{z}^\alpha}{\partial x^j}-\sum_\alpha\frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\alpha}{\partial x^j}$. No cal calcular tots els termes en detall, perquè molts contenen $1/\lambda$ o $1/\lambda^2$ i, per tant, convergeixen uniformement a $0$ quan $\lambda\to\infty$. Altres termes es cancel·len. CALDRIA FER AIXÒ A MÀ.
    \item $\lambda$ no fa desaparèixer els termes en què s'ha derivat les trigonomètriques, perquè en surt una $\lambda$ de dins. Ara bé, ens queden termes de l'estil $\sum_\alpha\frac{\partial z^\alpha}{\partial x^i}\zeta^\alpha\sqrt{a_\nu}(-\sin(\lambda \psi^\nu))\frac{\partial\psi^\nu}{\partial x^j}$, o amb les $i$ i $j$ bescanviades o amb $\eta^\alpha$ en comptes del $\zeta^\alpha$. Cadascun d'aquests termes són $0$, ja que $\zeta$ i $\eta$ són normals a la immersió.
    \item La resta de termes tindran el producte de dues funcions trigonomètriques o el quadrat d'una d'elles. Les que tinguin el producte també contenen $\zeta^\alpha\eta^\alpha$, i desapareixen per ortogonalitat.
    \item El que queda, doncs és 
    $$\sum_\alpha (\zeta^\alpha)^2 a_\nu (\sin^2(\lambda \psi^\nu) ) \frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + \sum_\alpha (\eta^\alpha)^2 a_\nu (\cos^2(\lambda \psi^\nu) ) \frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}$$
    i si traiem factor comú i usem que els vectors són unitaris, ens queda
    $$a_\nu\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}$$
    que és el que volíem.
    \item I amb això veiem que l'error mètric és $O(1/\lambda)$.
    \item A \textbf{Size of immersion...} repetim que la pertorbació canvia segons $O(1/\lambda)$ després de cada passa. Mirant el que fa a la primera derivada, veiem el canvi que fa en un entorn totes les passes d'una etapa, i queda que el canvi en les derivades acaba sent $$\left|\left( \frac{\partial z^\alpha}{\partial x^i}\right)_{\text{final}}-\left( \frac{\partial z^\alpha}{\partial x^i}\right)_{\text{inicial}}\right| \le 2\sqrt{K\beta_{ii}}+O(1/\lambda_1)+\dots + O(1/\lambda_\nu)+\cdots$$ LA VERITAT ÉS QUE NO SÉ D'ON SURTEN ELS TRES PUNTS DEL FINAL.
    \item A \textbf{Global considerations and convergence} volem veure quina $\lambda$ s'ha d'agafar. 
    \begin{itemize}
        \item[$\bullet$] $B_1$ és el màxim error que volem en l'aproximació del canvi mètric, \\$a_\nu\left(\frac{\partial\psi^\nu}{\partial x^i}\right)\left(\frac{\partial\psi^\nu}{\partial x^j}\right)$.
        \item[$\bullet$] $B_2$ és el màxim error $O(1/\lambda)$ que volem en el canvi de les primeres derivades.
        \item[$\bullet$] $B_3$ és la cota de $\overline{z}^\alpha - z^\alpha$.
    \end{itemize}
    \item Després d'una etapa, la nova mètrica induïda és $h'_{ij} = h_{ij} + \frac12\delta_{ij}$. Posem $h'_{ij} = g_{ij} - \delta'_{ij}$, on $\delta'_{ij} =-\frac12\delta_{ij} +e_{ij}$ i $e_{ij}$ és un terme d'error. Per tal que la successió convergeixi, necessitem que $\delta'_{ij}$ sigui estrictament més petita que $\delta_{ij}$. Si imposem que en tot punt de $N_p$ el màxim dels components de $e_{ij}$ sigui menor o igual a un sisè del màxim de $\delta_{ij}$, aleshores el màxim de $\delta'_{ij}$ serà menor o igual a dos terços del màxim de $\delta_{ij}$. MIRAR SI AIXÒ ÉS ALGUNA NORMA $C^k$ O ALGO.
    \item Volem que $\delta'_{ij}$ sigui definida positiva, que ho podem assegurar si imposem que la mida de $e_{ij}$ sigui més petita que un cert $\varepsilon_p$ que depèn de l'entorn compacte $N_p$. Com cada entorn se superposa amb un nombre finit $\sigma$ d'altres entorns, es poden trobar límits per $e_{ij}$ tal que el que busquem sigui cert en tots ells. Anomenem $\varepsilon_p^*$ el mínim d'aquestes limitacions.  
    \item L'error ve de l'aproximació de $\delta_{ij}$ per $\beta_{ij}$ i dels passos. Per tant, imposant $(\delta_{ij}- \beta_{ij}) < \varepsilon_p^*$, tenim que $(\frac12\varphi_p\delta_{ij}- \frac12\varphi_p\beta_{ij}) < \frac12\varepsilon_p^*$. Així, podem imposar que en un entorn $N_p$ els passos tinguin aquesta seqüència de $B_{1}$: $B_{11}\le\frac14\varepsilon_p^*$, $B_{12}\le\frac18\varepsilon_p^*$, $B_{13}\le\frac1{16}\varepsilon_p^*$, etc.
    \item A \textbf{Performability of the steps} simplement diu que a cada pas tenim una immersió $C^\infty$ i que tot és definit positiu. La única font de negativitat és l'error, però això sempre es pot contenir amb $\lambda$.
    \item A \textbf{General organization} es fa aquest resum:
        \begin{itemize}
            \item[$\bullet$] El procés es fa en una sèrie d'etapes que prenen una immersió curta $C^\infty$ i en retornen una amb un error mètric com a molt $2/3$ del de l'anterior.
            \item[$\bullet$] La varietat es divideix en entorns $N_p$. 
            \item[$\bullet$] Cada etapa es divideix en passos. A cada etapa, la correcció és pesada per $\varphi_p$ i dividida per tal que la duguin a terme les passes. 
            \item[$\bullet$] Si la varietat és oberta, hi ha un nombre infinit de passos per etapa, però a cada porció compacta hi ha un nombre finit.
        \end{itemize}
    \item A \textbf{Convergence of the immersion} diu que necessitem que les $B_3$ del pas $r$ de l'etapa $s$ siguin més petites que $2^{-(r+s)}$, i el mateix per $B_2$. La manera per fer-ho és escollir que la mida de $\beta_{ij}$ estigui entre $9/10$ i $9/8$ de la de $\delta_{ij}$. Això fa que el canvi en les derivades estigui limitat per una geomètrica de raó $\sqrt{5/6}$ MIRAR AIXÒ, de manera que les funcions $C^\infty$ convergeixen uniformement a una de $C^1$.
    \item ES MOLT IMPORTANT QUE ESCRIVIM ALGUNA COSA SOBRE LA DIFERÈNCIA ENTRE IMMERSIONS I encabiments.
    \item A \textbf{Isometric Imbeddings} {\color{black!50!green} QUAN PARLA DE CONJUNT LÍMIT CREC QUE ES REFEREIX A LA PART DEL CONJUNT OBERT MÉS LLUNYANA, EL QUE ESTARIA JUST A TOCAR DE LA FRONTERA} diu que per encabiments és bàsicament el mateix, però necessitem controlar les auto-interseccions. Per veure que pas a pas no n'hi ha, cal comprovar que per $\lambda$ prou gran les evitem. 
    \item Sigui $M$ un conjunt tancat de l'encabiment que conté $N_p$ al seu interior. $M$ té un entorn obert $H$ tal que no hi ha punt de $H$ amb dues rectes perpendiculars a $M$. MIRAR AIXÒ, HI HA UNA CITA.
    \item Posem $Q$ la unió del conjunt límit amb la part de la encabiment que no està a l'interior de $M$. Aleshores $Q$ és tancat i una pertorbació prou petita de $N_p^*$ no afectarà $Q$. AQUÍ NO SÉ QUÈ ÉS $N_p^*$. EN GENERAL, AQUEST APARTAT ES POSA MOLT TÈRBOL. 
    \item A \textbf{Constructing the initial immersion} explica que si la varietat té dimensió $n$, sabem que es pot trobar una encabiment en $E^{2n}$ no-singular i analítica. Es pot prendre aquesta immersió i escalar-la per a que sigui curta. 
    \item Per un conjunt obert, podem recobrir la varietat per entorns $N_p$ pesats amb funcions $C^\infty$ $\varphi_p$ amb paràmetres $x_{pi}$ tals que $|x_{pi}|\le1$. Volem que en qualsevol punt de la varietat els conjunts d'aquest recobriment se superposin un nombre finit de vegades $s$, com a molt.
    \item Podem dividir els conjunts $N_p$ en $s$ classes, de manera que en cada classe no hi hagi conjunts que es superposin. 
    \item Podem definir una encabiment en un espai $s(n+2)$ dimensional, a partir de funcions $u_\sigma=\varepsilon_p\varphi_p$ en conjunts de la classe $\sigma$ i $0$ en la resta, $v_\sigma=\varepsilon^2_p\varphi_p$ en conjunts de la classe $\sigma$ i $0$ en la resta, i $w_\sigma=\varepsilon_p\varphi_px_{pi}$ en conjunts de la classe $\sigma$ i $0$ en la resta, on $x_{pi}$ la coordenada $i$-èssima de $N_p$ i $\set{\varepsilon_p}_p$ és una successió monòtona decreixent de nombres positius que convergeix a $0$.
    \item Observem: que totes aquestes funcions són $C^\infty$, que dos punts de conjunts interiors a conjunts diferents tenen raons $v_\sigma/u_\sigma$ diferents, i que punts interiors a un mateix entorn $N_p$ tenen $w_{\sigma i}$ diferents. (EL CONJUNT LÍMIT ÉS L'ORIGEN PERÒ CAP PUNT ÉS ENVIAT A L'ORIGEN)
    \item Podem escollir que la encabiment sigui curta escollint la successió $\set{\varepsilon_p}_p$. Si la mètrica induïda pels primers $p$ entorns és curta per un factor $\frac13(2-1/p)$, podem escollor $p+1$ tal que sigui curta per un factor $1/3(2-1/(p+1))$. Amb això tenim una encabiment curta i $C^\infty$ en $E^{s(n+2)}$, i a partir de projeccions podem arribar a $E^{2n+1}$
    \item A \textbf{General summary} enumera els quatre teoremes que ha demostrat en aquest article:
    \begin{itemize}
        \item[$\bullet$] \begin{teo}
            Qualsevol varietat riemanniana tancada de dimensió $n$ té una encabiment isomètrica $C^1$ en $E^{2n}$.
        \end{teo}
        \item[$\bullet$] \begin{teo}
            Qualsevol varietat riemanniana de dimensió $n$ té una immersió isomètrica $C^1$ en $E^{2n}$ i una encabiment isomètrica $C^1$ en $E^{2n+1}$.
        \end{teo}
        \item[$\bullet$] \begin{teo}
            Si una varietat riemanniana tancada de dimensió $n$ té una immersió o encabiment $C^\infty$ en $E^{k}$ amb $k\ge n+2$, aleshores també té una immersió o encabiment, respectivament, isomètrica en $E^{k}$.
        \end{teo}
        \item[$\bullet$] \begin{teo}
            Si una varietat riemanniana oberta de dimensió $n$ té una immersió o encabiment $C^\infty$ curta en $E^{k}$ amb $k\ge n+2$ que no se solapa amb el seu conjunt límit (si aquest existeix), aleshores també té una immersió o encabiment, respectivament, isomètrica en $E^{k}$ del mateix tipus.
        \end{teo}
    \end{itemize}
    \item Per últim, un comentari super interessant que fa és que potser es pot canviar $n+2$ per $n+1$ si es fa una una pertorbació diferent que només necessita una direcció, que crec que és just el que fa Kuiper!
\end{itemize}

}









\begin{equation}\label{eq:un_mig_de_phi_p}
    \frac12\varphi_p\beta_{ij} = \sum_{\nu}a_{\nu}\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}
\end{equation}
\begin{lema}
    L'equació \eqref{eq:un_mig_de_phi_p} es pot satisfer amb les condicions necessàries.
\end{lema}
{\color{black!50!green}\textit{Prova.} Les matrius simètriques definides positives formen un con de dimensió $\frac12n(n+1)$.{\color{blue} D'on surt això? És molt estrany} És possible cobrir aquest con amb conjunts simplicials {\color{blue} MIRAR A WIKIPEDIA EL QUE ÉS} geomètrics oberts, de tal manera que cada punt del con estigui cobert per, com a molt, un nombre $W$ d'aquests entorns, on $W$ depèn només de $n$. 

Una matriu qualsevol representada per un punt d'un símplex és combinació lineal de les matrius que representen els vèrtexs del símplex. Podem posar
$$\begin{aligned}
    &C_{1,1}; \quad C_{1,2}; \quad C_{1,3}; \quad \dots\\
    &C_{2,1}; \quad C_{2,2}; \quad C_{2,3}; \quad \dots\\
    &\vdots\\
    &C_{q,1}; \quad C_{q,2}; \quad C_{q,3}; \quad \dots
\end{aligned}$$
els coeficients per $q$ representacions d'una matriu del con.
Ara podem escriure uns altres coeficients
$$ C_{\mu,\nu}^* = \frac{C_{\mu,\nu} \exp\set{-\sum_\sigma 1/C_{\mu,\sigma}}}{\sum_{\rho}\exp\set{-\sum_\sigma 1/C_{\rho,\sigma}}}, $$
de manera que aquests coeficients són $C^\infty$ com a funcions de la matriu que representen. Per cada matriu, com a molt $W[\frac12n(n+1)+1]$ coeficients $C_{\mu,\nu}^*$ són no-nuls.

Si ara considerem que $\beta_{ij}$ defineix una aplicació $C^\infty$ de $N_p$ al con, aleshores podem escriure 
\begin{equation}
    \beta_{ij} = \sum_{\mu,\nu}C_{\mu,\nu}^*M_{(\mu,\nu)ij}
\end{equation}
on $M_{(\mu,\nu)ij}$ són les diferents matrius que representen els vèrtexs dels símplexs. Ara, per cada matriu $M_{(\mu,\nu)ij}$ obtenim $n$ autovectors unitaris ortogonals $\set{V_r}$ i els seus autovalors $\set{v_r}$.

Si $\psi_r$ és per cada $r$ la funció lineal dels paràmetres locals pels quals $\sqrt{v_r}V_r$ és el vector gradient {\color{blue}Aquesta és la part més rara, entenc que simplement es pot fer}, tenim que
\begin{equation}
    M_{(\mu,\nu)ij} = \sum_{r}\frac{\partial\psi_r}{\partial x^i}\frac{\partial\psi_r}{\partial x^j}
\end{equation}
i, substituint en \eqref{eq:beta_con}, tenim que
\begin{equation}
    \beta_{ij} = \sum_{r}\sum_{\mu,\nu}C_{\mu,\nu}^*M_{(\mu,\nu)ij}\frac{\partial\psi_r}{\partial x^i}\frac{\partial\psi_r}{\partial x^j}
\end{equation}
i, agrupant termes en $a_\nu$, obtenim el resultat.\qed
}




























\newpage
\section{Explicació del Sung-Jin Oh}
\begin{teo}\label{teo: SJO} Sigui $(M,g)$ una superfície, $N\ge\dim M+1$ i $u:M\to\mathbb R^N$ una encabiment estrictament curta, és a dir, tal que la longitud de cada vector en $M$ s'escurça (estrictament) sota $\nabla u$. Aleshores $u$ es pot aproximar uniformement per encabiments isomètriques $C^1$.
\end{teo}
{\color{blue} Haurem d'explicar què és una encabiment isomètrica, i mirar si cal que li canviem el nom}

Per exemple, l'homotècia $\mathbb S^2\to\varepsilon\mathbb S^2$ amb $\varepsilon\in(0,1)$ és una aplicació \textit{curta}. 
\begin{obs}
De fet, qualsevol encabiment $C^2$ isomètrica $u:\mathbb S^2\hookrightarrow\mathbb R^3$ ha de ser igual a la encabiment estàndard $\mathbb S^2 \hookrightarrow\set{ x\in\mathbb R^3 : |X| = 1 }$ fins translació i rotació. 
\end{obs}

El teorema \ref{teo: SJO} es demostra amb \textit{integració convexa}.

Sung-Jin Oh demostra aquí el Baby Nash theorem.


Sigui $D=\set{x\in\mathbb R^2 : |x|<1}$ el disc unitat, i $g = g_{ij}(x)$ una mètrica de $D$. Una aplicació $u:D\to\mathbb R^n$ és una \textit{immersió} {\color{blue} per ara direm encabiment als embeddings i immersions als \textit{immersions}} si $\nabla u(x)$ és injectiva per tot $x$. La mètrica en $D$ induïda per $u$ és de la forma {\color{blue} Haurem de recordar i controlar el que era la mètrica induïda}
\begin{equation*}
    \nabla u ^{\intercal}(x)\nabla u (x) = \begin{pmatrix}
    \nabla_1 u\nabla_1 u & \nabla_1 u\nabla_2 u\\
    \nabla_2 u\nabla_1 u & \nabla_2 u\nabla_2 u
    \end{pmatrix}
\end{equation*}
Diem que l'aplicació és \textit{isomètrica} {\color{blue} també estaria bé comentar isometries} si $\nabla u ^{\intercal}\nabla u = g$, i diem que és \textit{(estrictament) curta} si $\nabla u(x)^{\intercal} \nabla u(x) - g(x) \le 0$ per tot $x\in D$.
\begin{teo}\label{Baby Nash} [Baby Nash]
    Sigui $n\ge 4$ i $u:D\to\mathbb R^n$ una immersió estrictament curta. Per qualsevol $\varepsilon > 0$, existeix una immersió isomètrica $C^1$ $\tilde u:D\to\mathbb R^n$ tal que $\|u-\tilde u\|_{C^0(D)} < \varepsilon$.{\color{blue} Aquí cal motivar l'interès d'aquest resultat. Entenc que la idea és que partim d'una immersió que és estrictament curta i volem trobar una que sigui contínua i isomètrica. Vull mirar continuïtats.}
\end{teo}
\begin{obs}
    Aquest teorema necessita que la co-dimensió sigui com a mínim 2.
\end{obs}
La manera de demostrar aquest resultat és a través d'un mètode iteratiu amb passos altament oscil·lants.
Sigui $u_1 = u + U$ amb 
\begin{equation*}
    U=\sum_{I\in\mathcal I} U_I
\end{equation*}
Volem que cada component $U_I^j$ sigui complex, per tal que oscil·li com $e^{ix \cdot \xi}$, però que el resultat del sumatori sigui real. Així, imposem que per cada $I\in\mathcal I$ que existeixi $\overline I\in\mathcal I$ tal que 
\begin{equation*}
    U_{\overline{I}} = \overline{U}_I, \quad \overline{\overline{I}} = I.
\end{equation*}
Ara tenim un error mètric $h_1 = g - \nabla u_1 ^{\intercal}\nabla u_1$. {\color{blue} On entenem que l'error mètric és la diferència entre la mètrica i la mètrica induïda per la immersió? Té sentit, però cal veure per què només agafo el primer terme.}
\begin{equation*}
    h_1 = 
        \left( h-\sum_{I} \nabla \overline{U}_I ^{\intercal}\nabla U_I \right) 
        - \sum_{I}\left( \nabla u ^{\intercal}\nabla U_I + \nabla U_I ^{\intercal}\nabla u \right)
        - \sum_{I,J: J\not = \overline I} \nabla U_I ^{\intercal}\nabla U_J.
\end{equation*}
I anomenem els tres sumands, en ordre, $q_{\text{mèt}}$, $q_{\text{lin}}$ i $q_{\text{alt}}$.

Volem una correcció que oscil·li en una sola direcció $\xi\in\mathbb R^2$, $|\xi|=1$. Posem
\begin{equation*}
    U_I = W = \frac1\lambda a(x)\textbf{n}(x)e^{\lambda i x \cdot \xi},
\end{equation*}
amb $a:D\to\mathbb R$ i $\textbf{n}:D\to\mathbb C^n$ tal que $\textbf{n}\cdot \overline{\textbf{n}}=1$. Per tal que sigui real, definim també $\overline I\in\mathcal I$ tal que 
\begin{equation*}
    U_{\overline{I}} = \overline W = \frac1\lambda a(x)\overline{\textbf{n}}(x)e^{-\lambda i x \cdot \xi}.
\end{equation*}

Per eliminar el terme $q_{\text{mèt}}$, observem que
\begin{equation*}
    \begin{aligned}
    \nabla_j W &= i\xi_j a(x)\textbf{n}(x)e^{\lambda i x \cdot \xi} + \frac{1}{\lambda}\nabla_j (a(x)\textbf{n}(x))e^{\lambda i x \cdot \xi}\\
    &=i\xi_j a(x)\textbf{n}(x)e^{\lambda i x \cdot \xi} + O(\frac{1}{\lambda})
    \end{aligned}
\end{equation*}
{\color{blue} EXPLICAR PER QUÈ ÉS O(1/LAMBDA)!!! De fet, explicar d'on surt la lambda aquesta.}
I, per tant,
\begin{equation*}
    \begin{aligned}
    \nabla_i W^*(x) \nabla_jW(x)&= (-i\xi_ia(x)e^{-\lambda i x \cdot \xi})(i\xi_ja(x)e^{\lambda i x \cdot \xi})\overline{\textbf{n}}(x) \cdot\textbf{n}(x) + O(\frac{1}{\lambda})\\
    &= \xi_i\xi_j a(x)^2 + O(\frac{1}{\lambda})
    \end{aligned}
\end{equation*}
on definim $(\cdot)^* = (\overline{\cdot})^\intercal$. Així, l'oscil·lació és cancel·lada i en resulta un terme $a(x)^2\xi_i\xi_j$.
\begin{ex}
    {\color{blue} EXPLICAR MILLOR AQUEST EXEMPLE}
    Posem que per un cert $x\in D$, l'error $h$ és de la forma
    \begin{equation*}
        h(x) = a^2(x)\xi \otimes \xi + b^2(x)\xi' \otimes \xi' + c^2(x)\xi'' \otimes \xi''
    \end{equation*}
    aleshores, amb això fem desaparèixer el terme $\xi \otimes \xi$. Repetint-ho per $\xi' \otimes \xi'$ i $\xi'' \otimes \xi''$ aconseguim reduir l'error $h(x)$ a un terme $O(\frac{1}{\lambda})$.
\end{ex}
\begin{obs}
    {\color{blue} EXPLICAR AQUESTA OBSERVACIÓ}
    Aquest mètode requereix que $h$ sigui curta, ja que $\nabla_i W^*(x) \nabla_jW(x)$ és un terme no-negatiu. De fet, per tal que $h_1$ sigui curt, necessitem que $h$ sigui estrictament curt.
\end{obs}
Ara bé, els autovectors $\xi$ depenen d'$x$. Això es pot resoldre amb el següent lema.
\begin{lema}\label{lema:descomposicio_error_metric} (Descomposició de l'error mètric)
    Sigui $\mathcal P$ l'espai de totes les matrius definides positives. Existeix una successió $\xi^{(k)}$ de vectors unitaris en $\mathbb R^n$ i una successió $\Gamma_{(k)}\in C_c^\infty(\mathcal P; [0,\infty))$ tals que
    \begin{equation*}
        A_{ij} = \sum_k\Gamma^2_{k}(A)\xi_i^{(k)}\xi_j^{(k)}
    \end{equation*}
    i aquesta suma és \textit{localment finita}. És a dir, existeix $N\in\mathbb N$ tal que per tot $A\in\mathcal P$ com a màxim $N$ termes de $\Gamma_{(k)}$ són no-nuls.
\end{lema}
\begin{obs}
    La demostració d'aquest teorema no l'escrivim aquí explícitament. {\color{blue} ESTÀ AL SUNG-JIN OH.}
\end{obs}
Fins ara no ha calgut especificar el vector $\textbf{n}(x)\in\mathbb C^n$ per tal de minimitzar l'error mètric, més enllà que necessitem que sigui unitari. Veurem que el podem escollir de tal manera que els termes $q_{\text{lin}}$ i $q_{\text{alt}}$ desapareguin fins a terme $O(1/\lambda)$.
\begin{itemize}

    \item \textbf{Error de linearització.} Substituïm el terme amb $W$
    \begin{equation*}
         \nabla_i u ^{\intercal}\nabla_j W = i\xi_j a(x)e^{ix\cdot\xi}\nabla_i u\cdot\textbf{n}+O(1/\lambda)
    \end{equation*}
    i veiem que podem eliminar aquest component escollint un vector perpendicular a l'espai tangent de $u(x)$, $\textbf{n}(x)\perp \nabla_j u(x)$. Això es pot fer perquè l'espai té co-dimensió 1 ({\color{blue}REVISAR!!!}). Podem fer el mateix amb $\nabla_iW^{\intercal}\nabla_ju$ i obtenim
    \begin{equation*}
        \nabla_i u ^{\intercal}\nabla_j W + \nabla_iW^{\intercal}\nabla_ju = O(1/\lambda)
    \end{equation*}

    \item \textbf{Interferència altament oscil·lant.} De nou, substituïm el terme
    \begin{equation*}
        \nabla_iW^{\intercal}\nabla_jW = (-a^2(x)\xi_i\xi_je^{2ix\cdot\xi})\textbf{n}\cdot\textbf{n} + O(1/\lambda).
    \end{equation*}
    I ara només cal utilitzar que la encabiment té co-dimensió $\ge2$ per escollir un vector complex tal que $\textbf{n}\cdot\textbf{n} = 0$ {\color{blue}Com està definit aquest producte?}. Podem prendre, per exemple, 
    \begin{equation*}
        \textbf{n} = \frac{1}{i\sqrt2}\zeta(x) + \frac{1}{\sqrt2}\eta(x)
    \end{equation*}
    on $\zeta(x)$ i $\eta(x)$ són vectors reals unitaris ortogonals a l'espai tangent $T_{u(x)}u(D)$.
    \item \textbf{Forma final de la correcció.} Tot plegat, tenim una correcció de la forma
    \begin{equation*}
        W(x) = \frac{a(x)}{\lambda}\left( \sin(\lambda x \cdot \xi)\zeta(x) + \cos(\lambda x \cdot \xi)\eta(x) \right)
    \end{equation*}
    amb les següents propietats:
    \begin{itemize}
        \item[--] Norma $C^0$ petita {\color{blue} Explicar C-normes}: $$||W||_{C^0}\le C\frac{||a||_{C^0}}{\lambda}$$
        \item[--] Terme principal en $\nabla W$ 
        \begin{equation*}
            \begin{aligned}
                \nabla W = &a(x)\left( \cos(\lambda x \cdot \xi)\zeta(x) - \sin(\lambda x \cdot \xi)\eta(x) \right) \\
                &+ O_{||a||_{C^0}, ||\nabla a||_{C^0}, ||\nabla\zeta||_{C^0}, ||\nabla\eta||_{C^0}}(1/\lambda)
            \end{aligned}
        \end{equation*}
        \item[--] Error mètric petit: $$\nabla_i W^{\intercal}\nabla_j W(x) -a^2(x)\xi_i\xi_j = O(1/\lambda)$$
        \item[--] Error de linearització petit: $$\nabla_i u ^{\intercal}\nabla_j W + \nabla_iW^{\intercal}\nabla_ju = O(1/\lambda)$$
        \item[--] Error d'interferència petita: $$\nabla_i W ^{\intercal}\nabla_j W = O(1/\lambda)$$
    \end{itemize}
\end{itemize}
\begin{obs}
    {\color{blue} Aquesta derivada es pot entendre si l'escrius i fas els passos. Mirar si cal explicar-ho millor.}
    Una manera alternativa d'arribar a la forma general de la correcció és la següent. Definim 
    \begin{equation*}
        \begin{aligned}
        \gamma = (\gamma_1, \gamma_2) : &D\times \mathbb T\to \mathbb R^2\\
        & (x,t)\mapsto \gamma(x,t)
        \end{aligned}
    \end{equation*}
    on $\mathbb T = \mathbb R / 2\pi\mathbb Z$.
    Posant $\dot\gamma$ la derivada respecte de $t$, tenim que
    \begin{equation*}
        \nabla W ^{\intercal}(x) \nabla W(x) = \left( \dot\gamma_1^2(x, \lambda x\cdot\xi) + \dot\gamma_2^2(x, \lambda x\cdot\xi) \right)\xi\otimes\xi + O(1/\lambda).
    \end{equation*}
    De manera que per cada $x$ cal trobar $\gamma(x,\cdot)$ tal que 
    (1) $\dot\gamma_1^2 + \dot\gamma_2^2 = a^2$ i 
    (2) $t\mapsto \dot\gamma(x,t)$ sigui $2\pi$-periòdic i $\int\dot\gamma\text{d}t = 0$
    De manera que $t\mapsto\gamma(x,t)$ també ha de ser $2\pi$-periòdica i el seu origen ha de pertànyer al disc unitat tancat $\overline D$.
    {\color{blue} IMPORTANT Per a després, NASH ANOMENA STEP A CADA ADDICIÓ D'UNA CORRECCIÓ, que es carrega un terme a un error d'ordre $O(1/\lambda)$. }
\end{obs}
\begin{lema}[Lema d'iteració]\label{Lema_iteracio}
    Sigui $u:D\to\mathbb R^n$ una immersió suau estrictament curta, tal que $h:=g-\nabla u ^{\intercal}\nabla u$ obeeix
    \begin{equation}
        ||h||_{C^0} \le e_h
    \end{equation}
    per algun $e_h > 0$. Aleshores, per qualsevol $\varepsilon > 0$, existeix una immersió suau estrictament curta $u_{[1]} = u + U$, on
    \begin{equation}
        \begin{aligned}
        ||U||_{C^0(D)} &\le \varepsilon\\
        ||\nabla U||_{C^0(D)} &\le Ce_h^{1/2}
        \end{aligned}
    \end{equation}
    i $h_{[1]}:=g-\nabla u_{[1]}^{\intercal}\nabla u_{[1]}$ obeeix
    \begin{equation}
        ||h_{[1]}-h||_{C^0} \le \varepsilon.
    \end{equation}
\end{lema}
\textit{Prova.} Pel lema \ref{lema:descomposicio_error_metric}, tenim que $h$ es pot escriure com
\begin{equation*}
    h(x) = \sum_k \Gamma^2_{(k)}(h(x))\xi^{(k)}\otimes\xi^{(k)}
\end{equation*}
on per cada $h(x)$ hi ha com a molt $K$ termes no-nuls.

Per la compacitat d' $h(D)\subseteq\mathcal P$, existeix un nombre finit de sumands que són funcions no-nul·les{\color{blue} Non-vanishing, mirar la traducció}. Reanomenem aquests sumands d'aquesta manera:
\begin{equation*}
    \Gamma^2_{(1)}(h(x))\xi^{(1)}\otimes\xi^{(1)}, \Gamma^2_{(2)}(h(x))\xi^{(2)}\otimes\xi^{(2)}, \dots, \Gamma^2_{(N)}(h(x))\xi^{(N)}\otimes\xi^{(N)}
\end{equation*}
Prenent la traça, veiem que 
\begin{equation*}
    ||\Gamma_{(j)}(h)||_{C^0} \le ||h||_{C^0}^{1/2} \le e_h^{1/2}
\end{equation*}
{\color{blue} Mirar d'on surt això (Sembla Cauchy-Schwarz, però què passa amb la traça de h?)}
Ara podem fer $N$ correccions a $u$ de la mateixa manera que hem fet abans, en les direccions $\xi^{(1)}, \xi^{(2)}, \dots, \xi^{(N)}$, per cancel·lar aquests errors. En concret, per un $\delta>0$, definim de manera recursiva $u_j = u_{j-1}+(1-\delta)^{1/2}U_j$, amb $u_0 = u$ i 
\begin{equation*}
    U_j = \frac{\Gamma_{(j)}(h(x))}{\lambda_j}\left( \sin(\lambda_j x\cdot\xi^{(j)})\zeta_j(x) + \cos(\lambda_j x\cdot\xi^{(j)})\eta_j(x) \right)
\end{equation*}
per uns certs $\lambda_j$ i $\zeta_j, \eta_j:D\to\mathbb R^n$ unitaris.

Prenem $\delta > 0$ per tal d'assegurar curtedat estricta {\color{blue} no sé com es diu shortness la veritat}. De fet, fixem $0<\delta<\frac{\varepsilon}{2e_h^{1/2}}$ per tal que $h\ge\delta I$. {\color{blue} uiuiui això mirar-ho bé}

Escollint $\lambda_j$ prou gran, tenim
\begin{itemize}
    \item[--]
    \begin{equation}
        ||U_j||_{C^0} \ll \varepsilon
    \end{equation}
    \item[--]
    \begin{equation}
        \nabla U_j = \Gamma_{(j)}(h)\xi^{(j)}(\cos(\lambda_j x\cdot\xi^{(j)})\zeta - \sin(\lambda_j x\cdot\xi^{(j)})\eta) + \text{err}_j,\quad ||\text{err}_j||_{C^0} \ll \varepsilon
    \end{equation}
    \item[--]
    \begin{equation}
        h_j=h_{j-1}-(1-\delta)\Gamma^2_{(k)}(h)\xi^{(j)}\xi^{(j)} + \text{err}_j', \quad ||\text{err}_j'||_{C^0} \ll \delta^2
    \end{equation}
    {\color{blue} Les dues primeres són fàcils d'entendre, però la tercera l'hem de revisar.}
\end{itemize}
On $h_j=g-\nabla u_j ^{\intercal}\nabla u_j$. 

Per tal de concloure la prova, verifiquem que $U=U_1+\dots+U_N$ i $u_{[1]}=u_N=u+U$ satisfan les propietats desitjades.

\begin{itemize}
    \item És fàcil veure que $||U_j|| \ll \varepsilon$ implica $||U||_{C^0(D)} \ll \varepsilon$.
    \item A més, de $\nabla U_j = \Gamma_{(j)}(h)\xi^{(j)}(\cos(\lambda_j x\cdot\xi^{(j)})\zeta - \sin(\lambda_j x\cdot\xi^{(j)})\eta) + \text{err}_j$ i $||\Gamma_{(j)}(h)||_{C^0} \le e_h^{1/2}$ tenim que $||\nabla U||_{C^0(D)} \le Ke_h^{1/2} + \sum_{j=1}^N ||\text{err}_j||_{C^0} \le 2Ke_h^{1/2}$ si es prenen les constants adequades. 
    \item Finalment, sumant els termes $h_j$ obtenim 
    \begin{equation*}
        h_N = h-(1-\delta)\sum_{j=1}^N \Gamma^2_{(j)}(h)\xi^{(j)}\xi^{(j)} + \sum_{j=1}^N \text{err}'_j = \delta h + \sum_{j=1}^N \text{err}'_j
    \end{equation*}
    i imposant que $u_{[1]} = u_N$ sigui estrictament curta, $h_{[1]}=h_N \ge \delta^2 I$, obtenim el resultat.
\end{itemize}
\qed

Ara podem iterar diverses vegades per concloure la prova del teorema \ref{Baby Nash}.

\textit{Prova del teorema \ref{Baby Nash}.} Sigui $e_{h,[k]}>0$ una successió tal que
$$\sum_{k}e_{h,[k]}\le \epsilon,\quad\sum_{k}e_{h,[k]}^{1/2}<\infty.$$ 
Pel lema \ref{Lema_iteracio}, obtenim una successió d'aplicacions suaus estrictament curtes $u_{[k]}$ tal que $u_{[0]}=u$ i
\begin{equation*}
    \begin{aligned}
    ||g-\nabla u_{[k]}^\intercal\nabla u_{[k]}||_{C^0} &\le e_{h,[k]}\\
    ||\nabla u_{[k+1]}-\nabla u_{[k]}||_{C^0} &\le Ce^{1/2}_{h,[k]}\\
    ||u_{[k+1]}-u_{[k]}||_{C^0} &\le e_{h,[k+1]},
    \end{aligned}
\end{equation*}
demostrant el teorema.\qed

{\color{blue} revisar això últim perquè just estava parlant amb la marina}
\subsection{Extensions}
\subsubsection{Extensió a encabiments de varietats}
Per estendre el teorema \ref{Baby Nash} a immersions a superfícies generals, només cal reduir a cartes coordenades. Per estendre'l a encabiments usem que, per la compacitat d'$M$, podem trobar $\varepsilon>0$ tal que 
$$\inf_{x,y} \text{dist}(u(x), u(y))\ge\varepsilon.$$ Ara només cal dur a terme la construcció en un entorn de $0.01\varepsilon$.{\color{blue} entendre millor això últim perquè és bastant random}
\subsubsection{Refinament de Kuiper: encabiment de codimensió 1}
Modificant la forma de la correcció, podem aconseguir la mateixa construcció amb només co-dimensió 1. Sigui $\eta:D\to\mathbb R^{3}$ el camp vectorial unitari en $u(D)$, i sigui
$$\zeta = \nabla u (\nabla u^\intercal \nabla u)^{-1}\xi.$$
Prenem 
$$U = \frac1\lambda \left( \gamma_{1}(x, \lambda x \cdot \xi)\tilde{\zeta}(x) + \gamma_{2}(x, \lambda x \cdot \xi)\tilde{\eta}(x) \right)$$
on 
$$\tilde{\zeta} = \frac{\zeta}{|\zeta|^2}, \quad \tilde{\eta} = \frac{\eta}{|\zeta|},$$
i $u_1 = u + U$. Això porta a 
{\color{blue} paper i boli}
$$\nabla u_1^\intercal \nabla u_1 = \nabla u^\intercal \nabla u +\frac{1}{|\zeta|^2}\left( 2\dot\gamma_{1} + \dot\gamma_1^2 + \dot\gamma_{2}^2 \right) \xi \otimes \xi + O(1/\lambda).$$
De manera que per cada $x$ i $a=a(x)\in\mathbb R$ volem que $\gamma$ sigui tal que
\begin{itemize}
    \item {\color{blue} posar això amb la cosa aquella de (1) i (2)}
    \item $(1+\dot\gamma_1)^2+\dot\gamma_2^2=|\zeta|^2a^2+1$,
    \item $t \mapsto \dot\gamma(x,t)$ és $2\pi$-periòdica i $\int\dot\gamma\textrm{d}t=0$
\end{itemize}
i tal que $|\dot\gamma|\le C|a|$. Això és possible perquè l'envolupant convexa de $\set{(x,y):(1+x)^2+y^2 = |\zeta|^2a^2+1}$ conté el $0$. 




\newpage
\section{Varietats topològiques}
\begin{defi} 
    Sigui $M$ un espai topològic. Diem que $M$ és una \textbf{varietat topològica de dimensió $n$} si es compleixen les propietats següents:
    \begin{itemize}
        \item $M$ és \underline{Hausdorff}, és a dir, si per a cada $p,q\in M$ amb $p\neq q$ existeixen entorns oberts $U\subseteq M$ i $V\subseteq M$ de $p$ i $q$ respectivament tals que $U\cap V = \emptyset$,
        \item $M$ verifica el \underline{segon axioma de numerabilitat}, és a dir, existeix una base numerable de la topologia de $M$,
        \item $M$ és \underline{localment homeomorf a $\mathbb R^n$}, és a dir, per a cada $p\in M$ existeix un entorn obert $U\subseteq M$ de $p$ que és homeomorf a un obert de $\mathbb R^n$.
    \end{itemize}
\end{defi}
{\color{blue} Es pot posar un exemple}

Per tal de poder descriure localment els punts de les varietats i de poder operar amb ells, serà útil introduir el concepte de carta coordenada.

\begin{defi}
    Sigui $M$ una varietat topològica de dimensió $n$. Diem que un parell $(U,\varphi)$ és una \textbf{carta coordenada de $M$} si $U$ és un obert de $M$ i $\varphi:U\to\hat U$ és un homeomorfisme amb un obert $\hat U\subseteq\mathbb R^n$. Anomenem $U$ el \textbf{domini de la carta} i $\varphi$ la \textbf{funció coordenada}.
\end{defi}
\begin{obs}
    De la definició de carta coordenada, observem que no tota varietat topològica $M$ es pot cobrir amb una única carta coordenada. Per exemple, si $M$ és homeomorf al cercle $\mathbb S^1$ amb la topologia induïda per $\mathbb R^2$, no es pot trobar cap aplicació $\varphi:M\to\mathbb R$ que sigui un homeomorfisme amb un obert de $\mathbb R$, ja que $\mathbb S^1$ és compacte.
\end{obs}

{\color{blue} Es pot posar un exemple.}

A continuació, donarem algunes propietats de les varietats topològiques i les cartes coordenades, sense reproduir les demostracions explícitament.

\begin{lema}
    Tota varietat topològica es pot recobrir amb numerables cartes coordenades.
\end{lema}


\begin{lema}
    Tota varietat topològica té una base numerable de boles coordenades amb adherència compacta.
\end{lema}


\begin{prop}
Sigui $M$ una varietat topològica. Aleshores, 
\end{prop}
{
    \begin{itemize}
        \item \textit{$M$ és localment arc-connexa.}{\color{blue} Aquí utilitzo arc-connexa com a sinònim de connex per camins.}
        \item \textit{$M$ és connex si i només si és arc-connex.}
        \item \textit{Els components connexos de $M$ són els seus components arc-connexos.}
        \item \textit{$M$ té un conjunt numerable de components connexos, i cada un d'ells és un obert i una varietat topològica connexa.}
    \end{itemize}
}
\begin{prop}
    Tota varietat topològica és localment compacta. És a dir, per a cada $p\in M$ existeix un entorn obert $U$ de $p$ tal que $U\subseteq K$ per algun compacte $K\subseteq M$.
\end{prop}
\begin{defi}
    Diem que una col·lecció $\mathcal X$ de subconjunts d'un espai topològic $M$ és \textbf{localment finita} si per a cada $p\in M$ existeix un entorn obert $U$ de $p$ tal que $U\cap X = \emptyset$ per a tots $X\in\mathcal X$ excepte un nombre finit d'ells.
\end{defi}
\begin{defi}
    Donat un recobriment per oberts $\mathcal U$ d'un espai topològic $M$, diem que un recobriment per oberts $\mathcal V$ és un \textbf{subrecobriment de $\mathcal U$} si per a cada $V\in\mathcal V$ existeix $U\in\mathcal U$ tal que $V\subseteq U$.
\end{defi}
\begin{defi}
    Diem que un espai topològic $M$ és \textbf{paracompacte} si qualsevol recobriment per oberts de $M$ té un subrecobriment localment finit.
\end{defi}
\begin{teo}
    Tota varietat topològica és paracompacta. De fet, donat un recobriment per oberts $\mathcal X$ i qualsevol base $\mathcal B$ de la topologia de $M$, existeix un subrecobriment numerable localment finit $\mathcal V$ de $\mathcal X$ format només d'elements de $\mathcal B$.
\end{teo}
{\color{blue} Aquesta demostració està en el Lee, no té gaire a veure amb el tema així que potser no la posem, però bueno, allà està.}
\section{Estructura suau}













\newpage
\section{Suavitat}
{\color{blue} L'Ignasi m'ha dit que el que hauria de ressaltar més és la diferència entre $C^1$ i $C^\infty$. Potser podria comentar alguns dels resultats que són vàlids en un i no en l'altre?}
{\color{blue} El que hi ha aquí ho estic traient de wikipedia. Preguntar a l'Ignasi per una font més bona.}
\begin{defi}
    Sigui $U\subseteq\mathbb R$ un conjunt obert, $f:U\to\mathbb R$ una funció real contínua.
    Diem que $f$ és {\normalfont $k$-vegades derivable contínuament}, amb $k\in\mathbb N_0$, si la derivada d'ordre $k$, $$f^{(k)}:= \frac{d^k}{dx^k}f,$$ existeix i és contínua en $U$. Anomenem l'índex $k$ \textit{suavitat} de $f$.
    Diem que $f$ és {\normalfont suau} o {\normalfont infinitament derivable} si existeix la derivada de qualsevol ordre.
\end{defi}
\begin{obss}
\end{obss}
\begin{itemize}
    \item $f$ és $0$ vegades derivable contínuament si i només si $f$ és contínua. 
    \item Si $f$ és $k$ vegades derivable contínuament, aleshores també és $j$ vegades derivable contínuament per $0\le j\le k$.
\end{itemize}
\begin{defi}
    Anomenem \textit{classe de diferenciabilitat} $C^k(U)$, amb $k\in\mathbb N_0$ l'espai de les funcions $k$-vegades derivables contínuament en $U\subseteq\mathbb R^n$. Anomenem $C^\infty(U)$ l'espai de les funcions infinitament derivables en $U$.
\end{defi}
De la mateixa manera, podem definir aquests conceptes per funcions de diverses variables.
\begin{defi}
    Sigui $U\subseteq\mathbb R^n$ un conjunt obert, $f:U\to\mathbb R$ una funció real contínua.
    Diem que $f$ és \textit{$k$-vegades derivable contínuament}, amb $k\in\mathbb N_0$, si totes les seves derivades parcials d'ordre $k$, $$\frac{\partial^k}{\partial x_1^{\alpha_1}\cdots\partial x_n^{\alpha_n}}f,$$ tals que $\sum_{i=1}^n\alpha_i = k$, existeixen i són contínues en $U$. És a dir, si $f$ és $k$-vegades derivable contínuament en cada component de $U$.
\end{defi}
\begin{defi}
    Anomenem \textit{classe de diferenciabilitat} $C^k(U)$, amb $k\in\mathbb N_0$ l'espai de les funcions $k$-vegades derivables contínuament en $U\subseteq\mathbb R^n$. Anomenem $C^\infty(U)$ l'espai de les funcions infinitament derivables en $U$.
\end{defi}
\begin{obss}{\color{blue} Potser caldria donar la definició explícita en el cas de funcions de diverses variables.}
\end{obss}
\begin{itemize}
    \item Moltes vegades, en lloc de $C^k(U)$ es fa servir $C^k(U;\mathbb R^m)$ per a funcions $f:U\to\mathbb R^m$.
    \item També escriurem simplement $C^k$ en lloc de $C^k(U)$ si el domini és clar pel context.
\end{itemize}

\subsection{Classes de diferenciabilitat com espais normats}
A continuació definirem normes en $C^k(U)$ i $C^\infty(U)$ que ens permetran tractar-les com espais vectorials normats.
\begin{defi}
    Sigui $U\subseteq\mathbb R^n$ un conjunt obert, $f:U\to\mathbb R^m$ una funció. Definim la norma $\|\cdot\|_{C^k(U)}$ de $f$ com
    \begin{equation*}
        \|f\|_{C^k(U)} = \sum_{|\alpha|\le k} \|D^\alpha f\|_{L^\infty(U)},
    \end{equation*}
    on $\|\cdot\|_{L^\infty(U)}$ és la norma del suprem en $U$, tal que $\|g\|_{L^\infty(U)} = \sup_{x\in U} |g(x)|$.
\end{defi}
{\color{blue} Aquí podríem proposar i demostrar que $\|\cdot\|_{C^k(U)}$ és efectivament una norma, ho tenim a \url{https://proofwiki.org/wiki/C%5Ek_Norm_is_Norm}. També cal decidir si definim explícitament la $D^\alpha$.}

\section{Fonaments de geometria diferencial}
Aquí hauriem de parlar d'embedding preferiblement.






\newpage
\section{Temes de les reunions}
Sigui $\mathcal M$ una varietat diferenciable amb una distància $d$, i sigui $$\nu = \set{(x,v)\in \mathcal M \times \mathbb R^n: v\in T_x\mathcal M^{\perp}}.$$ Per qualsevol $\varepsilon > 0$, definim el subconjunt $$\nu_\varepsilon = \set{(x,v)\in \nu: ||v|| < \varepsilon}$$
i l'aplicació $$\begin{aligned}
    \sigma:\nu_\varepsilon &\to \mathbb R^n \\
    (x,v) &\mapsto x+v
\end{aligned}$$
\begin{teo}
    Si $\varepsilon$ és prou petit, aleshores $\sigma:\nu_\varepsilon \to \sigma(\nu_\varepsilon)$ és homeomorfisme.
\end{teo}
{\color{black!50!green}\textit{Prova. (Meva, està molt millor al John M. Lee)} Primer, volem veure que $\sigma$ és injectiva. Suposem que $\mathcal M$ és $C^\infty$ (amb $C^2$ hauria de ser prou). Donat qualsevol punt $x\in\mathcal M$ existeix un entorn prou petit $U_x$ de $x$ en $\mathcal M$ tal que $\nu_1$ és injectiva. Això és degut al fet que, localment, la varietat és aproximadament igual al seu espai tangent. 

Sigui $x_0$ el punt amb l'entorn $U_{x_0}$ més petit que verifica la propietat anterior, i sigui $y_0$ el punt de $\mathcal M\setminus U_{x_0}$ tal amb el vector $w_0\in T_{y_0}\mathcal M$ més curt tal que existeix algun $v_0\in T_{x_0}\mathcal M$ tal que $x_0+v_0=y_0+w_0$. 
Sigui $l=||w_0||$. Aleshores, posant $\varepsilon = l/2$, tenim que $\sigma$ és injectiva. 

Pel que fa a la exhaustivitat, $\sigma:\nu_\varepsilon \to \sigma(\nu_\varepsilon)$ és exhaustiva per definició. A més, en ser la suma de dos vectors en $\mathbb R^n$, $\sigma$ és contínua.

Cal veure que la inversa $\sigma^{-1}$ és contínua. Sigui $a\in \sigma(\nu_\varepsilon)$. Aleshores, existeixen $x\in \mathcal M$ i $v\in \mathbb R^n$ tals que $a=\sigma(x,v)=x+v$. Com $\sigma^{-1}$ projecta punts de $\sigma(\nu_\varepsilon)$ en el punt de $\nu_\varepsilon$ més proper, tenim que $\sigma^{-1}$ és contínua.
Per tant, $\sigma$ és un homeomorfisme. \qed}
\begin{obs} 
    D'aquí surt el que fa servir Nash per allò del conjunt que no admet dues perpendiculars.
\end{obs}
\newpage