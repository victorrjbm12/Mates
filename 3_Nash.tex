\chapter{Teorema Nash-Kuiper $C^1$}
\section{Introducció al capítol}
En aquesta secció enunciarem i demostrarem els quatre teoremes d'immersions isomètriques $C^1$ de John Forbes Nash Jr., seguint l'article en què els va publicar el 1954 a Annals of Mathematics, \cite{nash1954}.\\
{\color{blue} explicar una mica el context i tal. Bàsicament, dir que és un teorema sorprenent perquè no se l'esperava ningú, explicar que el que fa és dividir en etapes i passos, i explicar que Kuiper fa una millora de la demostració de Nash per a una dimensió menys.

Important tornar a llegir i revisar quan dic successió i quan dic sèrie.}
\section{Enunciat dels teoremes}
{\color{blue} Hauria de fer servir $\mathbb R^k$ en comptes de $E^k$?}
\begin{teo}
    Qualsevol varietat Riemanniana tancada de dimensió $n$ té un encabiment isomètric $C^1$ en $E^{2n}$.
\end{teo}
\begin{teo}
    Qualsevol varietat Riemanniana de dimensió $n$ té una immersió isomètrica $C^1$ en $E^{2n}$ i un encabiment isomètric $C^1$ en $E^{2n+1}$.
\end{teo}
\begin{teo}
    Si una varietat Riemanniana tancada de dimensió $n$ té una immersió o encabiment $C^\infty$ en $E^{k}$ amb $k\ge n+2$, aleshores també té una immersió o encabiment, respectivament, isomètric en $E^{k}$.
\end{teo}
\begin{teo}
    Si una varietat Riemanniana oberta de dimensió $n$ té una immersió o encabiment $C^\infty$ curta en $E^{k}$ amb $k\ge n+2$ que no se solapa amb el seu conjunt límit (si aquest existeix), aleshores també té una immersió o encabiment, respectivament, isomètric en $E^{k}$ del mateix tipus.
\end{teo}
\section{Demostració}
Comencem amb una varietat diferenciable Riemanniana $M$ de dimensió $n$, amb una mètrica intrínseca donada per un tensor mètric $g_{ij}$. L'objectiu principal serà trobar una immersió isomètrica d'aquesta varietat $M$ en algun espai euclidià.

Suposem que tenim una immersió de $M$ en un espai euclidià $\mathbb R^k$.
\begin{align*}
    f:M&\to \mathbb R^k \\
    \set{x^i} &\mapsto \set{z^\alpha(x^1, \dots, x^n)} 
\end{align*}
Aleshores, la mètrica induïda en $M$ és 
\begin{equation}
    h_{ij} = \sum_\alpha \frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\alpha}{\partial x^j}.
\end{equation}
Per tal de començar la demostració, el primer que necessitarem serà una immersió $f$ que sigui de classe $C^\infty$ i \textit{curta}.
\begin{defi}
    Una immersió $f:M\to \mathbb R^k$ és \textbf{curta} si la diferència de les mètriques $g_{ij}-h_{ij}$ és definida positiva.
\end{defi}
El més important d'aquesta definició és que, si $f$ és curta, els vectors sobre $M$ mai s'allarguen sota $f$. Aquesta primera immersió $f$ és fàcil de trobar, en general, per a varietats tancades, mentre que per a varietats obertes cal entrar en més detalls. {\color{blue}  AQUÍ CITAR LA PART ON ES FA.}

Un cop trobada aquesta immersió curta, l'estructura de la demostració dels teoremes de Nash consisteix en fer una successió de pertorbacions de $f$ que, progressivament, disminueixen l'error mètric fins a trobar una immersió isomètrica en el límit. En general, el procés de pertorbació es divideix en \textbf{etapes} (en anglès, \textit{stages}), i a cada etapa es divideix en \textbf{passos} (en anglès, \textit{steps}). Així, la primera etapa prendrà la nostra immersió curta $f$ i en retornarà una $f_1$ amb un error mètric com a molt la meitat del de $f$, que serà també $C^\infty$ i curta. Aquesta $f_1$ serà millorada en la segona etapa, i així successivament.

La manera en què l'error mètric disminueix en cada etapa és la següent: en la primera immersió, l'error mètric és 
\begin{equation}
    \delta_{ij} = g_{ij}-h_{ij}.
\end{equation}
En la segona etapa, l'error mètric serà
\begin{equation}
    \overline\delta_{ij} = g_{ij}-\overline{h}_{ij}\approx \frac12\delta_{ij},
\end{equation}
on $\overline{h}_{ij}$ és la mètrica induïda per $f_1$. Aquest error mètric anirà disminuint geomètricament després de cada etapa, i en el límit obtindrem una immersió isomètrica.

En cada etapa, el procés de pertorbació es divideix en passos. Cada pas afectarà només un entorn local de $M$, però s'hauran de dur a terme l'un rere l'altre, no simultàniament. Per tal de fer-ho, cal prendre un recobriment localment finit de $M$ per conjunts tancats $\set{N_p}_p$. És a dir, tals que $M$ és la unió de tots ells, i cada $N_p$ interseca només un nombre finit d'altres $N_q$. {\color{blue}  Al Lee crec que s'explica el fet que sempre es pot trobar aquest recobriment per tancats.}

Associarem a cada $N_p$ una funció ponderació $\varphi_p$ de classe $C^\infty$ positiva a l'interior de $N_p$ i nul·la fora d'ell i a la frontera. Definim aquestes funcions tals que la suma de totes les $\varphi_p$ valgui $1$ en qualsevol punt. {\color{blue} crec que això s'anomena una partició de la unitat. Mirar el Lee. } En cada entorn tancat, voldrem que l'error mètric $\delta_{ij}$ sigui reduït en $\frac12\varphi_p\delta_{ij}$ després d'una etapa. Per fer-ho, necessitem aproximar $\delta_{ij}$ per un tensor de classe $C^\infty$ i positiu $\beta_{ij}$.

Per tal de fer servir aquest $\beta_{ij}$ per a reduir l'error mètric, necessitem el següent resultat:
\begin{lema}
    Sigui $\beta_{ij}$ un tensor de classe $C^\infty$ i definit positiu, i sigui $\varphi_p$ seguint la definició de més amunt. Aleshores, es poden trobar funcions no-negatives $a_\nu$ de classe $C^\infty$ i un nombre finit de funcions lineals $\psi^\nu = \psi^\nu(x^1, \dots, x^n)$ tals que
\begin{equation}\label{eq:lema_descomp}
    \frac12\varphi_p\beta_{ij} = \sum_\nu a_\nu \left(\frac{\partial\psi^\nu}{\partial x^i}\right)\left(\frac{\partial\psi^\nu}{\partial x^j}\right),
\end{equation}
\end{lema}
\begin{obs}
    Cal remarcar que aquest lema només és cert si $\beta_{ij}$ és definit positiu, i que el nombre de termes del sumatori és finit.
\end{obs}
{\color{green!50!black}\textit{Prova} ({\color{blue} Aquesta és la demostració del Nash. És una mica llarga però s'entén bastant bé si la mires amb cura. El Sung-Jin Oh té una versió més curta amb una notació diferent.}).
El conjunt de les matrius simètriques definides positives de rang $n$ és un con de dimensió $\frac12n(n+1)$.{\color{blue} Revisar d'on surt això, sembla bastant directe mirant quins coeficients es poden canviar.} És possible cobrir aquest con amb conjunts simplicials geomètrics oberts, de tal manera que cada punt del con estigui cobert per, com a molt, un nombre $W$ d'aquests entorns, on $W$ depèn només de $n$. 

Una matriu qualsevol representada per un punt interior d'un símplex és combinació lineal de les matrius que representen els vèrtexs del símplex. Podem posar
$$\begin{aligned}
    &C_{1,1}; \quad C_{1,2}; \quad C_{1,3}; \quad \dots\\
    &C_{2,1}; \quad C_{2,2}; \quad C_{2,3}; \quad \dots\\
    &\vdots\\
    &C_{q,1}; \quad C_{q,2}; \quad C_{q,3}; \quad \dots
\end{aligned}$$
els coeficients per $q$ representacions diferents d'una matriu del con que pertany a l'interior de $q$ símplexs diferents. 
Ara podem escriure uns altres coeficients
$$ C_{\mu,\nu}^* = \frac{C_{\mu,\nu} \exp\set{-\sum_\sigma 1/C_{\mu,\sigma}}}{\sum_{\rho}\exp\set{-\sum_\sigma 1/C_{\rho,\sigma}}}, $$ on cal considerar que els exponencials són nuls si qualsevol dels termes del seu sumatori ho és. 
Observem que aquests coeficients són $C^\infty$ com a funcions de la matriu que representen. A més, per cada matriu, com a molt $W[\frac12n(n+1)+1]$ coeficients $C_{\mu,\nu}^*$ són no-nuls.

Si ara considerem que $\beta_{ij}$ defineix una aplicació de classe $C^\infty$ de $N_p$ al con, aleshores podem escriure 
\begin{equation}\label{eq:beta_con}
    \beta_{ij} = \sum_{\mu,\nu}C_{\mu,\nu}^*M_{(\mu,\nu)ij}
\end{equation}
on $M_{(\mu,\nu)ij}$ són les diferents matrius que representen els vèrtexs dels símplexs. Ara, per cada matriu $M_{(\mu,\nu)ij}$ obtenim $n$ autovectors unitaris ortogonals $\set{V_r}$ i els seus autovalors $\set{v_r}$.

Si $\psi_r$ és per cada $r$ la funció lineal dels paràmetres locals pels quals $\sqrt{v_r}V_r$ és el vector gradient {\color{blue}Aquesta és la part més rara, entenc que simplement es pot fer}, tenim que
\begin{equation}
    M_{(\mu,\nu)ij} = \sum_{r}\frac{\partial\psi_r}{\partial x^i}\frac{\partial\psi_r}{\partial x^j}
\end{equation}
i, substituint en \ref{eq:beta_con}, tenim que
\begin{equation}
    \beta_{ij} = \sum_{r}\sum_{\mu,\nu}C_{\mu,\nu}^*M_{(\mu,\nu)ij}\frac{\partial\psi_r}{\partial x^i}\frac{\partial\psi_r}{\partial x^j}
\end{equation}
i, agrupant termes en $a_\nu$, obtenim el resultat.\qed
}

\subsection{La pertorbació en un pas}
En el pas associat a $N_p$ en una etapa donada, caldrà fer una pertorbació de la immersió curta obtinguda anteriorment. Per fer-ho, Nash considera dos camps vectorials unitaris ortogonals entre ells i a la immersió en l'entorn $N_p$, representats per funcions de classe $C^\infty$, $\zeta^\alpha$ i $\eta^\alpha$. És a dir, compleixen les següents propietats:
\begin{align}
    \sum_\alpha (\zeta^\alpha)^2 = 1, \\
    \sum_\alpha (\eta^\alpha)^2 = 1, \\
    \sum_\alpha \zeta^\alpha\eta^\alpha = 0, \\
    \sum_\alpha \zeta^\alpha\frac{\partial z^\alpha}{\partial x^i} = \sum_\alpha \eta^\alpha\frac{\partial z^\alpha}{\partial x^i} = 0.
\end{align}
\begin{obs}
    {\color{blue} És possible que això ho expliqui en algun altre lloc, però per ara ho deixo aquí. Estaria bé explicar el canvi que fa Kuiper, si hi ha espai, que jo crec que sí.}

    El fet que Nash utilitzi dos camps vectorials unitaris ortogonals entre ells i a la immersió en l'entorn $N_p$ restringeix severament la utilitat del seu resultat. En concret, per varietats Riemannianes de dimensió $2$, com l'esfera o el tor, el que ens interessa idealment és obtenir immersions en l'espai euclidià tridimensional, per tal de poder-les representar visualment, mentre que el resultat de Nash dóna immersions en un espai euclidià de dimensió $4$. Afortunadament, com veurem més endavant, Nicolaas H. Kuiper va modificar lleugerament la prova de Nash per rebaixar la codimensió de l'espai euclidià de $k=2$ a $k=1$.
\end{obs}

Amb aquests camps vectorials, la pertorbació de la immersió curta $z^\alpha$ en un pas a l'entorn $N_p$ és
\begin{equation}\label{eq:pertorbacio}
    \boxed{\overline{z}^\alpha = z^\alpha + \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu) + \eta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\sin(\lambda \psi^\nu)}
\end{equation}
on $\lambda$ és una constant positiva tan gran com vulguem.

Ara cal veure que el canvi mètric $\sum_\alpha\frac{\partial\overline{z}^\alpha}{\partial x^i}\frac{\partial\overline{z}^\alpha}{\partial x^j}-\sum_\alpha\frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\alpha}{\partial x^j}$ és aproximadament igual al terme $\nu$ del sumatori de \ref{eq:lema_descomp}.

\begin{prop}\label{prop:mida_pertorbacio}
    El canvi mètric a l'entorn $N_p$ en el pas associat a $a_\nu$ i $\psi^\nu$ donat per \ref{eq:pertorbacio} compleix
    \begin{equation}\label{eq:pertorbacio_cota}
        \sum_\alpha\frac{\partial\overline{z}^\alpha}{\partial x^i}\frac{\partial\overline{z}^\alpha}{\partial x^j}-\sum_\alpha\frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\alpha}{\partial x^j} =  a_\nu \frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + O\left(\frac1\lambda\right)
    \end{equation}
\end{prop}

{\color{green!50!black}\textit{Prova}. Desenvolupant les derivades parcials i cancel·lant els termes que apareixen en ambdós costats, tenim
\begin{align}\label{eq:pertorbacio_descomp}
    \nonumber\sum_\alpha\frac{\partial\overline{z}^\alpha}{\partial x^i}\frac{\partial\overline{z}^\alpha}{\partial x^j}-\sum_\alpha\frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\alpha}{\partial x^j}
    =
    \sum_{\alpha}\Bigg[ &\frac{\partial}{\partial x^i}\left( \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu)\right) \frac{\partial}{\partial x^j}\left( \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu)\right) +
    \\
    &+ \frac{\partial}{\partial x^i}\left( \eta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\sin(\lambda \psi^\nu)\right) \frac{\partial}{\partial x^j}\left( \eta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\sin(\lambda \psi^\nu)\right)
    \Bigg]
\end{align}
Observem que cada en terme del sumatori apareixen quatre derivades similars, canviant $\zeta^\alpha$ per $\eta^\alpha$ i $\cos$ per $\sin$, així com $i$ per $j$. Podem considerar una sola d'aquestes, per exemple $\frac{\partial}{\partial x^i}\left( \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu)\right)$. Desenvolupant-la, tenim
\begin{align*}
    \frac{\partial}{\partial x^i}\left( \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu)\right)
    =&
    \left(\frac{\partial \zeta^\alpha}{\partial x^i} \right)\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu) 
    \\&+ 
    \zeta^\alpha\frac{1}{\lambda}\left(\frac{\partial}{\partial x^i}\sqrt{a_\nu}\right) \cos(\lambda \psi^\nu)
    \\&-
    \zeta^\alpha\sqrt{a_\nu}\sin(\lambda \psi^\nu)\frac{\partial\psi^\nu}{\partial x^i}.
\end{align*}
Observem que els dos primers termes d'aquesta suma són $O\left(\frac1\lambda\right)$, de manera que es pot prendre $\lambda$ prou gran per fer-los tan petits com vulguem. Així, 
\begin{equation*}
    \frac{\partial}{\partial x^i}\left( \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu)\right) = -
    \zeta^\alpha\sqrt{a_\nu}\sin(\lambda \psi^\nu)\frac{\partial\psi^\nu}{\partial x^i} + O\left(\frac1\lambda\right).
\end{equation*}
El producte d'aquest terme amb la derivada respecte de $x^j$ en \ref{eq:pertorbacio_descomp} és, per tant,
\begin{equation*}
    \frac{\partial}{\partial x^i}\left( \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu)\right) \frac{\partial}{\partial x^j}\left( \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu)\right) = 
    (\zeta^\alpha)^2{a_\nu}\sin^2(\lambda \psi^\nu)\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + O\left(\frac1\lambda\right).
\end{equation*}
Sumant aquest resultat amb el corresponent a $\eta^\alpha$, obtenim que el terme $\alpha$ del sumatori de \ref{eq:pertorbacio_descomp} és
\begin{align*}
    &(\zeta^\alpha)^2{a_\nu}\sin^2(\lambda \psi^\nu)\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + (\eta^\alpha)^2{a_\nu}\cos^2(\lambda \psi^\nu)\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + O\left(\frac1\lambda\right)
    \\&=
    ((\zeta^\alpha)^2\sin^2(\lambda \psi^\nu) + (\eta^\alpha)^2\cos^2(\lambda \psi^\nu)) a_\nu\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + O\left(\frac1\lambda\right).
\end{align*}
De manera que 
\begin{align*}
    \sum_\alpha\frac{\partial\overline{z}^\alpha}{\partial x^i}\frac{\partial\overline{z}^\alpha}{\partial x^j}-\sum_\alpha&\frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\alpha}{\partial x^j}=\\
    &=
    \sum_{\alpha}\Bigg[((\zeta^\alpha)^2\sin^2(\lambda \psi^\nu) + (\eta^\alpha)^2\cos^2(\lambda \psi^\nu)) a_\nu\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}
    + O\left(\frac1\lambda\right) \Bigg]
    \\
    &=a_\nu\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}\left( \sin^2(\lambda \psi^\nu)\sum_\alpha(\zeta^\alpha)^2 + \cos^2(\lambda \psi^\nu)\sum_\alpha(\eta^\alpha)^2\right) + O\left(\frac1\lambda\right)
    \\&=
    a_\nu\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + O\left(\frac1\lambda\right),
\end{align*}
on per a la darrera igualtat hem usat que $\sum_\alpha(\zeta^\alpha)^2 = \sum_\alpha(\eta^\alpha)^2 = 1$.\qed
}

Amb aquesta última proposició s'ha demostrat que la pertorbació indueix un canvi mètric molt proper al que volem, amb un error $O\left(\frac1\lambda\right)$. De la mateixa manera, observem que la pertorbació en un pas, \ref{eq:pertorbacio}, és $O\left(\frac1\lambda\right)$. A continuació, volem veure quin és el canvi en les primeres derivades després d'una etapa del procés en un entorn $N_p$. És a dir, volem aproximar l'efecte de totes les pertorbacions associades a cada pas de l'etapa. Per fer-ho, primer notem que el canvi en les primeres derivades associat al pas $\nu$ és el següent:
\begin{equation}\label{eq:primera_derivada_cota}
    \left| \frac{\partial\overline{z}^\alpha}{\partial x^i} - \frac{\partial z^\alpha}{\partial x^i} \right| \le 2\sqrt{a_\nu}\left| \frac{\partial\psi^\nu}{\partial x^i} \right| + O\left(\frac1\lambda\right).
\end{equation}
\begin{prop}
    El canvi en les primeres derivades associat a una etapa del procés en un entorn $N_p$ és
    \begin{align}\label{eq:moltes_lambdes}
        \nonumber\Bigg| \left(\frac{\partial{z}^\alpha}{\partial x^i} \right)_{\textrm{abans}}- &\left(\frac{\partial{z}^\alpha}{\partial x^i} \right)_{\textrm{després}} \Bigg| \\
        &\le 2\sqrt{K\beta_{ii}} + O\left(\frac1{\lambda_1}\right) + O\left(\frac1{\lambda_2}\right) + \cdots + O\left(\frac1{\lambda_\nu}\right) + \cdots,
    \end{align}
    on $K$ és una constant que depèn només de la dimensió $n$ de la varietat i les diferents $\lambda_\nu$ són els paràmetres de les pertorbacions.
\end{prop}
{
\color{green!50!black}\textit{Prova}.
Considerem l'element $i$ de la diagonal de les matrius de \ref{eq:lema_descomp}:
\begin{equation*}
    \frac12\varphi_p\beta_{ii} = \sum_\nu a_\nu\left(\frac{\partial\psi^\nu}{\partial x^i}\right)^2 = \sum_\nu \left(\sqrt{a_\nu}\left|\frac{\partial\psi^\nu}{\partial x^i}\right|\right)^2.
\end{equation*}
Recordem de la prova del lema \ref{eq:lema_descomp} que hi ha com a molt $M = W[\frac12n(n+1)+1]$ coeficients no nuls del sumatori, on $W$ és una constant que només depèn de la dimensió $n$ de la varietat. Així doncs, per la desigualtat de Cauchy-Schwarz,
\begin{align*}
    \sum_\nu \sqrt{a_\nu}\left|\frac{\partial\psi^\nu}{\partial x^i}\right| 
    \le 
    \left(M\frac12\varphi_p\beta_{ii}\right)^{\frac12}
    \le
    \left(K\varphi_p\beta_{ii}\right)^{\frac12}
    \le
    \sqrt{\left(K\beta_{ii}\right)}.
\end{align*}
Combinant aquest resultat amb \ref{eq:primera_derivada_cota}, obtenim que el canvi en les primeres derivades associat a una etapa del procés en un entorn $N_p$ és
\begin{equation*}
    \left| \frac{\partial\overline{z}^\alpha}{\partial x^i} - \frac{\partial z^\alpha}{\partial x^i} \right| \le \sqrt{K\beta_{ii}} + O\left(\frac1{\lambda_1}\right) + O\left(\frac1{\lambda_2}\right) + \cdots + O\left(\frac1{\lambda_\nu}\right) + \cdots.
\end{equation*}
\qed
}
\subsection{Convergència dels passos en una etapa}
{\color{blue} He de mirar si realment aquest és el títol que toca.}

A continuació ens interessa veure quines són les constants $\set{\lambda_\nu}$ necessàries en les diferents passes d'una etapa per tal que el procés convergeixi tal com desitgem.
\begin{defi}
    Sigui $N_p$ un entorn de $M$, i considerem el pas $\nu$ d'una etapa donada.
\end{defi}
\begin{itemize}\label{def: B1 B2 B3}
    \item \textit{Anomenem $B_1$ l'error d'ordre $O\left(\frac1{\lambda}\right)$ màxim permès en l'aproximació del canvi mètric per $a_\nu\left(\frac{\partial\psi^\nu}{\partial x^i}\right)\left(\frac{\partial\psi^\nu}{\partial x^j}\right)$ en \ref{eq:pertorbacio_cota}, per tots els parells $(i,j)$ i tots els punts de l'entorn $N_p$.}
    \item \textit{Anomenem $B_2$ l'error d'ordre $O\left(\frac1{\lambda}\right)$ màxim permès en l'aproximació del canvi de les primeres derivades en \ref{eq:primera_derivada_cota}, per tots els punts de l'entorn $N_p$.}
    \item \textit{Anomenem $B_3$ la cota superior permesa del canvi $\overline{z}^\alpha - z^\alpha$ en $N_p$.}
\end{itemize}
\begin{obs}
    Es pot trobar una pertorbació que compleixi les condicions anteriors per a qualsevol $B_1$, $B_2$ i $B_3$ donats, ja que tots tres disminueixen quan $\lambda$ augmenta i aquesta pot ser presa arbitràriament gran.
\end{obs}

Recordem que l'efecte desitjat després d'una etapa és prendre una mètrica induida $h_{ij}$ i trobar-ne una $h'_{ij}$ que redueixi a la meitat l'error mètric $\delta_{ij}$. És a dir, la nova mètrica $h'_{ij}$ ha de complir
\begin{equation}
    h'_{ij} =  \approx h_{ij} + \frac12\delta_{ij},
\end{equation}
que també podem escriure com 
\begin{equation}
    h'_{ij} = g_{ij} - \frac12\delta_{ij} + e_{ij},
\end{equation}
on $e_{ij}$ és el terme de l'error de l'aproximació. Així, la diferència entre la mètrica de la nova immersió i la original és
\begin{equation}\label{eq:delta_prima}
    \delta_{ij}' = \frac12\delta_{ij} - e_{ij}.
\end{equation}
A continuació, ens volem assegurar que $\delta_{ij}'$ sigui definit positiu, i que el tensor d'error $e_{ij}$ sigui prou petit per permetre la convergència del procés.
\begin{nota}
    Per un tensor donat $T_{ij}$ en un entorn $N_p$, escrivim $|T_{ij}|_{N_p}$ per denotar el màxim dels valors absoluts dels components de $T_{ij}$ en $N_p$. Aquesta és una bona aproximació de la mida del tensor $T_{ij}$ en $N_p$. {\color{blue} Cal mirar si hi ha una millor notació}
\end{nota}
\begin{prop}\label{prop:dos de tres}
    Sigui $N_p$ un entorn de $M$. En una etapa donada del procés, existeix una successió $\set{B_{1\nu}}_{\nu}$, on $B_{1\nu}$ és el $B_1$ de la definició \ref{def: B1 B2 B3} al pas $\nu$, tal que, després de fer tots els passos en $N_p$
\end{prop}
\begin{itemize}
    \item \textit{$\delta_{ij}'$ és definit positiu en $N_p$.}
    \item \textit{$e_{ij}$ és prou petit per assegurar que el procés convergeix després de fer totes les etapes.}
    \item \textit{La convergència és tal que la mida de $\delta_{ij}'$ és aproximadament $2/3$ de la mida de $\delta_{ij}$ després de cada etapa. }{\color{blue} No m'agrada gaire com està descrita aquesta proposició}
\end{itemize}
\begin{obs}
    Aquest resultat confirma que el procés convergeix, de tal manera que la immersió resultant després de realitzar totes les etapes és isomètrica. {\color{blue} Potser seria més correcte dir que la mètrica resultant és isomètrica, però encara no sabem si la immersió convergeix correctament.}
\end{obs}
{\color{green!50!black} \textit{Prova.} 
En $N_p$, sempre es pot trobar una constant real $\varepsilon_p>0$ tal que, si imposem 
\begin{equation}\label{eq:epsilon_p}
    |e_{ij}|_{N_p} \le \varepsilon_p,
\end{equation}
aleshores $\delta_{ij}'= \delta_{ij} - e_{ij}$ és definit positiu.

Si també imposem que, després d'una etapa,
\begin{equation}\label{eq:e_cota}
    \max|e_{ij}|_{N_p} \le \frac16\min|\delta_{ij}|_{N_p},
\end{equation}
podem prendre \ref{eq:delta_prima} i veure que
\begin{align}\label{eq:delta_prima_cota}
    \nonumber\max|\delta_{ij}'|_{N_p} = \max\left|\frac12\delta_{ij} - e_{ij}\right|_{N_p} \le \max\left|\frac12\delta_{ij}\right|_{N_p} + \max|e_{ij}|_{N_p} \\
    \le \frac12\max|\delta_{ij}|_{N_p} + \frac16\min|\delta_{ij}|_{N_p} \le \frac23\max|\delta_{ij}|_{N_p}.
\end{align}
Amb això queda demostrat que es pot escollir $e_{ij}$ tal que la mida de $\delta_{ij}'$ és aproximadament $2/3$ de la mida de $\delta_{ij}$ després de cada etapa. Així, és clar que la diferència entre la mètrica de la immersió i $g_{ij}$ convergeix a $0$ en el límit.

Hem obtingut dues restriccions a la mida de $e_{ij}$ que cal complir, \ref{eq:epsilon_p} i \ref{eq:e_cota}. Ara cal relacionar-les amb les passes de l'etapa, per tal d'obtenir la successió $\set{B_{1\nu}}_{\nu}$ desitjada. 

Primer de tot, recordem que els entorns $N_p$ poden intersecar amb altres entorns $N_q$. Així, els canvis que fem en $N_p$ poden afectar a $N_q$. Afortunadament, el nombre d'entorns que intersequen cada $N_p$ és finit. Si $N_p$ interseca amb $\sigma$ entorns $N_q$, incloent $N_p$ mateix, aleshores podem prendre les restriccions de $N_p$, dividir-les per $\sigma$, i imposar-les a tots els $N_q$. Sigui $\varepsilon_p^*$ el mínim de totes aquestes restriccions sobre l'error de $N_p$.

Notem que hi ha dues fonts de l'error en $N_p$: el primer és l'aproximació preliminar de $\delta_{ij}$ pel tensor $\beta_{ij}$, i el segon és l'error acumulat per les passes individuals. Per tant, imposant $|\delta_{ij}-\beta_{ij}|_{N_p} \le \varepsilon_p^*$ obtenim 
\begin{equation}\label{eq:error_aproximacio}
    \left|\frac12\varphi_p\delta_{ij}-\frac12\varphi_p\beta_{ij}\right|_{N_p} \le \frac12\varepsilon_p^*.
\end{equation}
Ens resta $\frac12\varepsilon_p^*$
per a l'error de les passes individuals, que podem assignar de la següent manera:
\begin{equation}\label{eq:error_passos}
    B_{1\nu} \le \frac{1}{2^{\nu+1}}\varepsilon_p^*.
\end{equation}
De manera que l'error total obtingut sumant \ref{eq:error_aproximacio} i \ref{eq:error_passos} és menor que
\begin{equation*}
    \frac12\varepsilon_p^* + \sum_{\nu=1}^\infty \frac1{2^{\nu+1}}\varepsilon_p^* = \varepsilon_p^*.
\end{equation*}
Així, obtenim la successió $\set{B_{1\nu}}_{\nu}$ desitjada.
\qed
}
\subsubsection{Realitzabilitat dels passos}
Per tal que els passos siguin realitzables, només cal tenir una immersió $C^\infty$. Això és cert sempre que la mètrica induida sigui definida positiva i les immersions siguin $C^\infty$. Totes les funcions utilitzades en el procés són $C^\infty$, de manera que només cal veure que la mètrica induida és definida positiva.

Procedim per inducció. Suposem que cada pas pas pren una immersió que produeix una mètrica induida definida positiva, i augmenta la mètrica induida en $a_\nu\left(\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}\right)$. Així, la mètrica induida és definida positiva. Aquest augment és un tensor no-negatiu, i l'error és $O\left(\frac1{\lambda}\right)$, de manera que per una $\lambda$ prou gran, ens podem assegurar que la mètrica induida és definida positiva.

\subsection{Organització general}
{\color{blue} Aquest apartat haurem de mirar de moure'l a un lloc més adequat, potser. }

\begin{itemize}
    \item El procés es divideix en una sèrie \textbf{d'etapes}. Cada una d'elles és igual que la resta, però la primera necessita una immersió $f$ de classe $C^\infty$ curta. Després de cada etapa, la nova immersió segueix sent $C^\infty$ i curta, però l'error mètric és aproximadament $2/3$ de l'error de la immersió de l'etapa anterior.
    \item S'escull un recobriment localment finit de $M$ per conjunts tancats $N_p$. És a dir, tal que cada punt de $M$ pertany a, com a molt, un nombre finit de conjunts $N_p$.
    \item Cada etapa es divideix en un nombre finit de \textbf{passos}. Primer, la correcció es divideix entre tots els conjunts $N_p$ amb unes funcions pes $\varphi_p$. Aleshores es divideix la correcció de cada $N_p$ en un nombre finit de passos, \ref{eq:lema_descomp}
    \item Els passos s'han de realitzar un rere l'altre. L'ordre concret no importa, però s'ha d'escollir un ordre i seguir-lo. En varietats obertes, el nombre de passes és infinit, però en cada entorn compacte el nombre de passos és finit.
\end{itemize}

\subsection{Convergència de la immersió}
Per la Proposició \ref{prop:dos de tres}, sabem que la mètrica resultant del procés en el límit és la mètrica intrínseca de la varietat, com volíem. Ara bé, encara no hem demostrat que convergeixi en una immersió $C^1$. El primer que cal assegurar és que el resultat en el límit és, efectivament, una immersió. Amb aquest fi, podem imposar que en el pas $r$ de l'etapa $s$ del procés, el corresponent $B_3$ estigui fitat per
\begin{equation}\label{eq:b3_cota}
    B_{3} \le \frac1{2^{(s+r)}},
\end{equation}
de manera que la successió dels $B_3$ sigui més petita que una successió convergent.

Imposant les mateixes fites per la successió de $B_2$, 
\begin{equation}
    B_2 \le \frac1{2^{(s+r)}},
\end{equation}
controlem els termes d'error d'ordre $O\left(\frac1{\lambda}\right)$ de l'equació \ref{eq:moltes_lambdes}. Ara bé, per tal que les primeres derivades convergeixin al final del procés, cal que el terme irreductible $2\sqrt{K\beta_{ii}}$ també convergeixi.

\begin{prop}
    La sèrie formada per la successió $\set{2\sqrt{K\beta_{ii}}}_{\nu}$ convergeix per cada $i$ i uniformement en cada entorn $N_p$.
\end{prop}
{
\color{green!50!black} \textit{Prova.} 
$K$ és una constant que només depèn de la dimensió $n$ de la varietat, de manera que només ens hem d'ocupar de $\beta_{ii}$.
El tensor $\beta_{ij}$ aproxima l'error mètric $\delta_{ij}$, que es redueix per un factor $1/3$ o major després de cada etapa, com hem vist a la desigualtat \ref{eq:delta_prima_cota} {\color{blue} Nash diu que això és després de cada pas, em fa pal ara mirar com és.}. Cal veure que $\beta_{ij}$ decreix de manera similar. Podem imposar que $\beta_{ij}$ sigui prou proper a $\delta_{ij}$ tal que 
\begin{equation}
    \frac{9}{10} \le \frac{\max|\beta_{ij}|_{N_p}}{\max|\delta_{ij}|_{N_p}} \le \frac{9}{8}.
\end{equation}
Aleshores,
\begin{equation}
    |\beta_{ij}'|_{N_p} \le \frac{9}{8}|\delta_{ij}'|_{N_p}\le \frac{9}{8}\frac{2}{3}|\delta_{ij}|_{N_p} \le \frac{9}{8}\frac{2}{3}\frac{10}{9}|\beta_{ij}|_{N_p} =  \frac{5}{6}|\beta_{ij}|_{N_p}.
\end{equation}
Així, el terme $\beta_{ii}$ decreix per un factor $5/6$ o major després de cada etapa. Per tant, la sèrie formada per la successió $\set{2\sqrt{K\beta_{ii}}}_{\nu}$ convergeix com una geomètrica de raó $\sqrt{5/6}$. \qed
}

\begin{obs}
    La conseqüència d'això és que, en el límit, la immersió $f$ és $C^1$, com volíem demostrar.
\end{obs}

\subsection{Encabiments isomètrics}

Fins ara hem estat tractant el cas de les immersions, per les quals no hi ha restricció pel que fa a les interseccions amb elles mateixes. Ara bé, per demostrar que el procés descrit per Nash també aplica als encabiments, que han de ser injectius, cal comprovar que les immersions resultants també ho són.

\begin{nota}
    Sigui $M$ una varietat oberta i $f:M\to \mathbb R^n$ un encabiment. Anomenem \textbf{frontera de l'encabiment} al conjunt $\partial f(M) = \overline{f(M)}\setminus f(M)$. {\color{blue} Ho deixo indicat perquè no sé si aquest és el terme estàndard, però no m'agrada com l'anomena el Nash.}
\end{nota}

La demostració per encabiments és la mateixa que per immersions generals, però l'aplicació $f$ de la que partim ha de ser un encabiment. Si la varietat és oberta, demanem també que la frontera de l'encabiment, si existeix, no intersequi la imatge de l'encabiment. Un cop es té aquest primer encabiment curt, la única consideració addicional és que s'ha de controlar la mida de l'encabiment $|\overline z^\alpha - z^\alpha|$ en cada pas.

Ens haurem de fixar primer en què cada pas es pugui fer sense que el nou encabiment intersequi amb si mateix, i després en què l'encabiment resultant en el límit del procés sigui injectiu.
\begin{obs}
    Si la varietat és oberta, l'elecció de $B_3$ a \ref{eq:b3_cota} assegura que la frontera de l'encabiment roman fix durant tot el procés.
\end{obs}
\begin{prop}
    En qualsevol pas d'una etapa i en qualsevol entorn $N_p$ de la frontera de l'encabiment, es pot escollir una $\lambda$ prou gran tal que el pas no produeixi interseccions de l'encabiment amb si mateix ni amb la frontera de l'encabiment.
\end{prop}
{
\color{green!50!black} \textit{Prova.} 
    Sigui $K$ un component compacte de l'encabiment que inclogui $N_p$ al seu interior. $K$, al seu torn, està inclòs en un entorn obert $H$ tan proper a $K$ tal que per qualsevol punt $P$ en $H$ no pot tenir dues perpendiculars a $K$ en $H$. {\color{blue} Això és el que vam parlar amb l'Ignasi. Podríem mirar si cal posar una demostració o un dibuixet o algo.}

    Sigui $Q$ la unió de la frontera de l'encabiment i la part de l'encabiment que no està inclòs en $K$. Com $Q$ és un conjunt tancat, una pertorbació prou petita no pot intersecar $Q$. A més, com la pertorbació és normal a l'encabiment, estarà dins de $H$ i els punts de $K$ no es podran intersecar. Així doncs, el pas no produeix interseccions de l'encabiment amb si mateix ni amb la frontera de l'encabiment.\qed
}

Amb aquest resultat, obtenim per inducció que en qualsevol nombre finit de passos del procés, l'encabiment no produeix interseccions amb si mateix ni amb la frontera de l'encabiment. Això no assegura que el límit del procés sigui injectiu després d'infinits passos, sinó que cal considerar això a part.

\begin{prop}
    Es pot escollir una successió dels $B_3$ tal que el límit del procés sigui injectiu, és a dir, tal que la immersió resultant sigui un encabiment.
\end{prop}
{
\color{green!50!black} \textit{Prova.} 
    Considerem una enumeració dels $N_p$ qualsevol. Sigui $S_r$ el conjunt de tots els parells de punts dels primers $r$ entorns tals que estaven separats per una distància major que $2^{-r}$ en l'encabiment curt original. Qualsevol parell de punts pertany a $S_r$ per algun $r$. A partir de l'etapa $r$ requerirem que el $B_3$ de l'etapa $\mu\le r$ i el pas $\nu$ sigui més petit que $\varepsilon_r2^{-\mu-\nu}$, on $\varepsilon_r$ s'escull prou petit per assegurar que cap parell de punts pugui ajuntar-se al límit. D'aquesta manera, tots els parells de punts queden protegits en el límit, i la immersió resultant és un encabiment. \qed
}
\subsection{Obtenint la immersió o l'encabiment inicial}
Amb tot el que hem demostrat fins aquí, ja hem vist que per qualsevol immersió o encabiment curt inicial $C^\infty$, es pot trobar una immersió o encabiment $C^1$ isomètric de la varietat en un espai euclidià. Només queda veure que es pot trobar aquesta immersió o aquest encabiment inicial. En aquesta subsecció expliquem el procés per obtenir-lo. 

En el cas d'una varietat tancada, podem obtenir l'encabiment inicial en $\mathbb R^{2n}$ mitjançant el teorema de Whitney. {\color{blue} Haurem de mirar d'explicar-lo.} Per tar de fer-lo curt, es pot canviar l'escala de l'espai euclidià.

En el cas d'una varietat oberta, s'escull un recobriment per tancats $N_p$ i unes funcions $\varphi_p$ de classe $C^\infty$que sumin $1$ en qualsevol punt, com abans, i denotem $x_{p_i}$ per la coordenada $i$-èssima de $N_p$. Suposem $|x_{p_i}|<1$ per a qualsevol $i$ i $p$. A més, imposem que cada $N_p$ interseca com a molt amb $s$ d'aquests conjunts, incloent-hi el mateix $N_p$. A continuació, separem els conjunts en $s$ classes, tals que cap conjunt té intersecció amb un altre de la mateixa classe. 

Construim un encabiment en un espai $s(n+2)$-dimensional $E^{s(n+2)}$ amb les següents funcions:
\begin{equation}
    u_\sigma = 
    \begin{cases}
        \varepsilon_p\varphi_p & \text{en entorns $N_p$ de la classe $\sigma$} \\
        0 & \text{en la resta d'entorns}
    \end{cases}
\end{equation}
\begin{equation}
    v_\sigma = 
    \begin{cases}
        \varepsilon_p^2\varphi_p & \text{en entorns $N_p$ de la classe $\sigma$} \\
        0 & \text{en la resta d'entorns}
    \end{cases}
\end{equation}
\begin{equation}
    w_{\sigma i} = 
    \begin{cases}
        \varepsilon_p\varphi_p x_{p i} & \text{en entorns $N_p$ de la classe $\sigma$} \\
        0 & \text{en la resta d'entorns}
    \end{cases}
\end{equation}
on $\varepsilon_p$ formen part d'una successió monòtona decreixent i convergent a $0$. Qualsevol parell de punts de la varietat en entorns diferents es pot distingir per tenir diferents conjunts de raons $u_\sigma/v_\sigma$, i qualsevol parell de punts en el mateix entorn es pot distingir pels $w_{\sigma i}$ corresponents. A més, la frontera de l'encabiment és l'origen de coordenades.

Per últim, aquesta immersió es pot fer curta escollint els $\varepsilon_p$ tal que, si la immersió amb els $p$ primers entorns és curta per un factor $\frac13(2-1/p)$ o més gran, prenem $\varepsilon_{p+1}$ prou petit perquè la immersió amb $p+1$ primers entorns sigui curta per un factor $\frac13(2-1/(p+1))$ o més gran. 

Amb això obtenim un encabiment curt de classe $C^\infty$ de la varietat en un espai $s(n+2)$-dimensional. Mitjançant projeccions lineals, podem rebaixar la dimensió de l'espai de l'encabiment fins a $2n+1$, i fins a $2n$ per a immersions.










































\newpage
\section{Apunts del paper de Nash del 1954}
{
\color{blue}
\begin{itemize}
    \item Parlar abans de la diferència entre el punt de vista extrínsec i intrínsec de la geometria, un cop haguem parlat de geodif. 
    \item Veurem que una varietat de dimensió $n$ es pot ficar en un espai $E^{2n}$, on aquí diem que $E^k$ és l'espai euclidià de dimensió $k$.
    \item Interessant que el procés de les correccions sempre augmenta les distàncies localment, motiu pel qual el primer ha de ser curt. Diu Nash que l'anem "estirant".
    \item Mirar el tema de si la caracterització de una immersió curta és diferent que a la que dona SJO.
    \item Si la varietat és tancada només cal canviar l'escala de $E^k$ per fer la immersió curta. Si és oberta cal fer una cosa més complicada.
    \item Coses a tenir en compte:
        \begin{itemize}
            \item $g_{ij}$ és la mètrica intrínseca, $h_{ij}$ és la mètrica induïda.
            \item $\set{x^i}$ són les coordenades en la varietat $M$.
            \item $\set{z^\alpha}$ són les coordenades en $E^k$.
            \item Amb la immersió, $z^\alpha = z^\alpha(x^1, \dots, x^n)$.
            \item La mètrica induïda és $h_{ij} = \frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\beta}{\partial x^j}$. Normalment estaria multiplicat per una $g_{\alpha\beta}$ que no apareix perquè en aquest cas és la mètrica euclidiana.
        \end{itemize}
    \item Cada correcció es va fent en infinites "etapes", cada una d'elles corregint la correcció de la etapa anterior. L'important aquí és que cada correcció manté el fet que la immersió sigui curta, tot i que cada vegada menys. Cada etapa ens hi hauria d'apropar la meitat del camí. Per exemple, després de la primera, l'error hauria de ser
    $$g_{ij}-\overline{h_{ij}}\approx \frac12(g_{ij}-h_{ij})$$
    \item Ho fem d'aquesta manera perquè així ens assegurem que cada correcció només ha d'augmentar la mètrica. 
    \item Cada etapa es divideix en passes (passos?), que afecten només localment la immersió augmentant la mètrica en una sola direcció. 
    \item Per tal de dividir en passos, dividim la varietat en una sèrie d'entorns amb $n$ paràmetres $C^\infty$ no singulars, i cada entorn es pot trobar amb un nombre finit d'altres entorns.
    \item Per cada un d'aquests entorns, per exemple $N_p$, prenem una funció $\varphi_p$ positiva a l'interior de $N_p$ i $0$ fora d'ell. Definim aquestes funcions tals que la suma de totes les $\varphi_p$ valgui $1$ en qualsevol punt. (Això com es fa? Diu que és estàndard però em sembla una mica complicat si ha de ser $C^\infty$.) Això serveix per distribuir la "càrrega" de la correcció.
    \item En cada entorn, la "càrrega" de la correcció es divideix també entre les passes. Sigui $\delta_{ij}=g_{ij}-h_{ij}$ l'error mètric després d'unes quantes etapes. A la propera voldríem augmentar la mètrica més o menys $\frac12\delta_{ij}$, de manera que a l'entorn $N_p$ voldríem augmentar la mètrica en $\frac12\varphi_p\delta_{ij}$. Per fer-ho haurem de trobar un tensor definit positiu $\beta_{ij}$ que sigui $C^\infty$ i aproximi $\delta_{ij}$.
    \item $$\frac12\varphi_p\beta_{ij} = \sum_{\nu}a_{\nu}\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}$$ on $x^i$ són coordenades de l'entorn $N_p$, $a_\nu$ funcions no-negatives $C^\infty$ i $\psi^\nu$ funcions lineals en $x^i$.
    \item A l'apartat \textbf{The normal fields}, diu que necessita dos camps vectorials unitaris $C^\infty$ normals a la immersió i ortogonals entre ells, $\zeta^\alpha$ i $\eta^\alpha$. Això és lo de la co-dimensió 2 que després Kuiper canvia a 1.
    \item La pertorbació associada a $a_\nu$ i $\psi^\nu$ és 
        \begin{equation}
            \boxed{\overline{z}^\alpha = z^\alpha + \zeta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\cos(\lambda \psi^\nu) + \eta^\alpha\frac{\sqrt{a_\nu}}{\lambda}\sin(\lambda \psi^\nu)}
        \end{equation}
        on $\lambda$ és un paràmetre que podem triar.
    \item El canvi mètric és $\sum_\alpha\frac{\partial\overline{z}^\alpha}{\partial x^i}\frac{\partial\overline{z}^\alpha}{\partial x^j}-\sum_\alpha\frac{\partial z^\alpha}{\partial x^i}\frac{\partial z^\alpha}{\partial x^j}$. No cal calcular tots els termes en detall, perquè molts contenen $1/\lambda$ o $1/\lambda^2$ i, per tant, convergeixen uniformement a $0$ quan $\lambda\to\infty$. Altres termes es cancel·len. CALDRIA FER AIXÒ A MÀ.
    \item $\lambda$ no fa desaparèixer els termes en què s'ha derivat les trigonomètriques, perquè en surt una $\lambda$ de dins. Ara bé, ens queden termes de l'estil $\sum_\alpha\frac{\partial z^\alpha}{\partial x^i}\zeta^\alpha\sqrt{a_\nu}(-\sin(\lambda \psi^\nu))\frac{\partial\psi^\nu}{\partial x^j}$, o amb les $i$ i $j$ bescanviades o amb $\eta^\alpha$ en comptes del $\zeta^\alpha$. Cadascun d'aquests termes són $0$, ja que $\zeta$ i $\eta$ són normals a la immersió.
    \item La resta de termes tindran el producte de dues funcions trigonomètriques o el quadrat d'una d'elles. Les que tinguin el producte també contenen $\zeta^\alpha\eta^\alpha$, i desapareixen per ortogonalitat.
    \item El que queda, doncs és 
    $$\sum_\alpha (\zeta^\alpha)^2 a_\nu (\sin^2(\lambda \psi^\nu) ) \frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j} + \sum_\alpha (\eta^\alpha)^2 a_\nu (\cos^2(\lambda \psi^\nu) ) \frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}$$
    i si traiem factor comú i usem que els vectors són unitaris, ens queda
    $$a_\nu\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}$$
    que és el que volíem.
    \item I amb això veiem que l'error mètric és $O(1/\lambda)$.
    \item A \textbf{Size of immersion...} repetim que la pertorbació canvia segons $O(1/\lambda)$ després de cada passa. Mirant el que fa a la primera derivada, veiem el canvi que fa en un entorn totes les passes d'una etapa, i queda que el canvi en les derivades acaba sent $$\left|\left( \frac{\partial z^\alpha}{\partial x^i}\right)_{\text{final}}-\left( \frac{\partial z^\alpha}{\partial x^i}\right)_{\text{inicial}}\right| \le 2\sqrt{K\beta_{ii}}+O(1/\lambda_1)+\dots + O(1/\lambda_\nu)+\cdots$$ LA VERITAT ÉS QUE NO SÉ D'ON SURTEN ELS TRES PUNTS DEL FINAL.
    \item A \textbf{Global considerations and convergence} volem veure quina $\lambda$ s'ha d'agafar. 
    \begin{itemize}
        \item[$\bullet$] $B_1$ és el màxim error que volem en l'aproximació del canvi mètric, \\$a_\nu\left(\frac{\partial\psi^\nu}{\partial x^i}\right)\left(\frac{\partial\psi^\nu}{\partial x^j}\right)$.
        \item[$\bullet$] $B_2$ és el màxim error $O(1/\lambda)$ que volem en el canvi de les primeres derivades.
        \item[$\bullet$] $B_3$ és la cota de $\overline{z}^\alpha - z^\alpha$.
    \end{itemize}
    \item Després d'una etapa, la nova mètrica induïda és $h'_{ij} = h_{ij} + \frac12\delta_{ij}$. Posem $h'_{ij} = g_{ij} - \delta'_{ij}$, on $\delta'_{ij} =-\frac12\delta_{ij} +e_{ij}$ i $e_{ij}$ és un terme d'error. Per tal que la successió convergeixi, necessitem que $\delta'_{ij}$ sigui estrictament més petita que $\delta_{ij}$. Si imposem que en tot punt de $N_p$ el màxim dels components de $e_{ij}$ sigui menor o igual a un sisè del màxim de $\delta_{ij}$, aleshores el màxim de $\delta'_{ij}$ serà menor o igual a dos terços del màxim de $\delta_{ij}$. MIRAR SI AIXÒ ÉS ALGUNA NORMA $C^k$ O ALGO.
    \item Volem que $\delta'_{ij}$ sigui definida positiva, que ho podem assegurar si imposem que la mida de $e_{ij}$ sigui més petita que un cert $\varepsilon_p$ que depèn de l'entorn compacte $N_p$. Com cada entorn se superposa amb un nombre finit $\sigma$ d'altres entorns, es poden trobar límits per $e_{ij}$ tal que el que busquem sigui cert en tots ells. Anomenem $\varepsilon_p^*$ el mínim d'aquestes limitacions.  
    \item L'error ve de l'aproximació de $\delta_{ij}$ per $\beta_{ij}$ i dels passos. Per tant, imposant $(\delta_{ij}- \beta_{ij}) < \varepsilon_p^*$, tenim que $(\frac12\varphi_p\delta_{ij}- \frac12\varphi_p\beta_{ij}) < \frac12\varepsilon_p^*$. Així, podem imposar que en un entorn $N_p$ els passos tinguin aquesta seqüència de $B_{1}$: $B_{11}\le\frac14\varepsilon_p^*$, $B_{12}\le\frac18\varepsilon_p^*$, $B_{13}\le\frac1{16}\varepsilon_p^*$, etc.
    \item A \textbf{Performability of the steps} simplement diu que a cada pas tenim una immersió $C^\infty$ i que tot és definit positiu. La única font de negativitat és l'error, però això sempre es pot contenir amb $\lambda$.
    \item A \textbf{General organization} es fa aquest resum:
        \begin{itemize}
            \item[$\bullet$] El procés es fa en una sèrie d'etapes que prenen una immersió curta $C^\infty$ i en retornen una amb un error mètric com a molt $2/3$ del de l'anterior.
            \item[$\bullet$] La varietat es divideix en entorns $N_p$. 
            \item[$\bullet$] Cada etapa es divideix en passos. A cada etapa, la correcció és pesada per $\varphi_p$ i dividida per tal que la duguin a terme les passes. 
            \item[$\bullet$] Si la varietat és oberta, hi ha un nombre infinit de passos per etapa, però a cada porció compacta hi ha un nombre finit.
        \end{itemize}
    \item A \textbf{Convergence of the immersion} diu que necessitem que les $B_3$ del pas $r$ de l'etapa $s$ siguin més petites que $2^{-(r+s)}$, i el mateix per $B_2$. La manera per fer-ho és escollir que la mida de $\beta_{ij}$ estigui entre $9/10$ i $9/8$ de la de $\delta_{ij}$. Això fa que el canvi en les derivades estigui limitat per una geomètrica de raó $\sqrt{5/6}$ MIRAR AIXÒ, de manera que les funcions $C^\infty$ convergeixen uniformement a una de $C^1$.
    \item ES MOLT IMPORTANT QUE ESCRIVIM ALGUNA COSA SOBRE LA DIFERÈNCIA ENTRE IMMERSIONS I encabiments.
    \item A \textbf{Isometric Imbeddings} {\color{black} QUAN PARLA DE CONJUNT LÍMIT CREC QUE ES REFEREIX A LA PART DEL CONJUNT OBERT MÉS LLUNYANA, EL QUE ESTARIA JUST A TOCAR DE LA FRONTERA} diu que per encabiments és bàsicament el mateix, però necessitem controlar les auto-interseccions. Per veure que pas a pas no n'hi ha, cal comprovar que per $\lambda$ prou gran les evitem. 
    \item Sigui $M$ un conjunt tancat de l'encabiment que conté $N_p$ al seu interior. $M$ té un entorn obert $H$ tal que no hi ha punt de $H$ amb dues rectes perpendiculars a $M$. MIRAR AIXÒ, HI HA UNA CITA.
    \item Posem $Q$ la unió del conjunt límit amb la part de la encabiment que no està a l'interior de $M$. Aleshores $Q$ és tancat i una pertorbació prou petita de $N_p^*$ no afectarà $Q$. AQUÍ NO SÉ QUÈ ÉS $N_p^*$. EN GENERAL, AQUEST APARTAT ES POSA MOLT TÈRBOL. 
    \item A \textbf{Constructing the initial immersion} explica que si la varietat té dimensió $n$, sabem que es pot trobar una encabiment en $E^{2n}$ no-singular i analítica. Es pot prendre aquesta immersió i escalar-la per a que sigui curta. 
    \item Per un conjunt obert, podem recobrir la varietat per entorns $N_p$ pesats amb funcions $C^\infty$ $\varphi_p$ amb paràmetres $x_{pi}$ tals que $|x_{pi}|\le1$. Volem que en qualsevol punt de la varietat els conjunts d'aquest recobriment se superposin un nombre finit de vegades $s$, com a molt.
    \item Podem dividir els conjunts $N_p$ en $s$ classes, de manera que en cada classe no hi hagi conjunts que es superposin. 
    \item Podem definir una encabiment en un espai $s(n+2)$ dimensional, a partir de funcions $u_\sigma=\varepsilon_p\varphi_p$ en conjunts de la classe $\sigma$ i $0$ en la resta, $v_\sigma=\varepsilon^2_p\varphi_p$ en conjunts de la classe $\sigma$ i $0$ en la resta, i $w_\sigma=\varepsilon_p\varphi_px_{pi}$ en conjunts de la classe $\sigma$ i $0$ en la resta, on $x_{pi}$ la coordenada $i$-èssima de $N_p$ i $\set{\varepsilon_p}_p$ és una successió monòtona decreixent de nombres positius que convergeix a $0$.
    \item Observem: que totes aquestes funcions són $C^\infty$, que dos punts de conjunts interiors a conjunts diferents tenen raons $v_\sigma/u_\sigma$ diferents, i que punts interiors a un mateix entorn $N_p$ tenen $w_{\sigma i}$ diferents. (EL CONJUNT LÍMIT ÉS L'ORIGEN PERÒ CAP PUNT ÉS ENVIAT A L'ORIGEN)
    \item Podem escollir que la encabiment sigui curta escollint la successió $\set{\varepsilon_p}_p$. Si la mètrica induïda pels primers $p$ entorns és curta per un factor $\frac13(2-1/p)$, podem escollor $p+1$ tal que sigui curta per un factor $1/3(2-1/(p+1))$. Amb això tenim una encabiment curta i $C^\infty$ en $E^{s(n+2)}$, i a partir de projeccions podem arribar a $E^{2n+1}$
    \item A \textbf{General summary} enumera els quatre teoremes que ha demostrat en aquest article:
    \begin{itemize}
        \item[$\bullet$] \begin{teo}
            Qualsevol varietat Riemanniana tancada de dimensió $n$ té una encabiment isomètrica $C^1$ en $E^{2n}$.
        \end{teo}
        \item[$\bullet$] \begin{teo}
            Qualsevol varietat Riemanniana de dimensió $n$ té una immersió isomètrica $C^1$ en $E^{2n}$ i una encabiment isomètrica $C^1$ en $E^{2n+1}$.
        \end{teo}
        \item[$\bullet$] \begin{teo}
            Si una varietat Riemanniana tancada de dimensió $n$ té una immersió o encabiment $C^\infty$ en $E^{k}$ amb $k\ge n+2$, aleshores també té una immersió o encabiment, respectivament, isomètrica en $E^{k}$.
        \end{teo}
        \item[$\bullet$] \begin{teo}
            Si una varietat Riemanniana oberta de dimensió $n$ té una immersió o encabiment $C^\infty$ curta en $E^{k}$ amb $k\ge n+2$ que no se solapa amb el seu conjunt límit (si aquest existeix), aleshores també té una immersió o encabiment, respectivament, isomètrica en $E^{k}$ del mateix tipus.
        \end{teo}
    \end{itemize}
    \item Per últim, un comentari super interessant que fa és que potser es pot canviar $n+2$ per $n+1$ si es fa una una pertorbació diferent que només necessita una direcció, que crec que és just el que fa Kuiper!
\end{itemize}

}









\begin{equation}\label{eq:un_mig_de_phi_p}
    \frac12\varphi_p\beta_{ij} = \sum_{\nu}a_{\nu}\frac{\partial\psi^\nu}{\partial x^i}\frac{\partial\psi^\nu}{\partial x^j}
\end{equation}
\begin{lema}
    L'equació \ref{eq:un_mig_de_phi_p} es pot satisfer amb les condicions necessàries.
\end{lema}
{\color{green!50!black}\textit{Prova.} Les matrius simètriques definides positives formen un con de dimensió $\frac12n(n+1)$.{\color{blue} D'on surt això? És molt estrany} És possible cobrir aquest con amb conjunts simplicials {\color{blue} MIRAR A WIKIPEDIA EL QUE ÉS} geomètrics oberts, de tal manera que cada punt del con estigui cobert per, com a molt, un nombre $W$ d'aquests entorns, on $W$ depèn només de $n$. 

Una matriu qualsevol representada per un punt d'un símplex és combinació lineal de les matrius que representen els vèrtexs del símplex. Podem posar
$$\begin{aligned}
    &C_{1,1}; \quad C_{1,2}; \quad C_{1,3}; \quad \dots\\
    &C_{2,1}; \quad C_{2,2}; \quad C_{2,3}; \quad \dots\\
    &\vdots\\
    &C_{q,1}; \quad C_{q,2}; \quad C_{q,3}; \quad \dots
\end{aligned}$$
els coeficients per $q$ representacions d'una matriu del con.
Ara podem escriure uns altres coeficients
$$ C_{\mu,\nu}^* = \frac{C_{\mu,\nu} \exp\set{-\sum_\sigma 1/C_{\mu,\sigma}}}{\sum_{\rho}\exp\set{-\sum_\sigma 1/C_{\rho,\sigma}}}, $$
de manera que aquests coeficients són $C^\infty$ com a funcions de la matriu que representen. Per cada matriu, com a molt $W[\frac12n(n+1)+1]$ coeficients $C_{\mu,\nu}^*$ són no-nuls.

Si ara considerem que $\beta_{ij}$ defineix una aplicació $C^\infty$ de $N_p$ al con, aleshores podem escriure 
\begin{equation}
    \beta_{ij} = \sum_{\mu,\nu}C_{\mu,\nu}^*M_{(\mu,\nu)ij}
\end{equation}
on $M_{(\mu,\nu)ij}$ són les diferents matrius que representen els vèrtexs dels símplexs. Ara, per cada matriu $M_{(\mu,\nu)ij}$ obtenim $n$ autovectors unitaris ortogonals $\set{V_r}$ i els seus autovalors $\set{v_r}$.

Si $\psi_r$ és per cada $r$ la funció lineal dels paràmetres locals pels quals $\sqrt{v_r}V_r$ és el vector gradient {\color{blue}Aquesta és la part més rara, entenc que simplement es pot fer}, tenim que
\begin{equation}
    M_{(\mu,\nu)ij} = \sum_{r}\frac{\partial\psi_r}{\partial x^i}\frac{\partial\psi_r}{\partial x^j}
\end{equation}
i, substituint en \ref{eq:beta_con}, tenim que
\begin{equation}
    \beta_{ij} = \sum_{r}\sum_{\mu,\nu}C_{\mu,\nu}^*M_{(\mu,\nu)ij}\frac{\partial\psi_r}{\partial x^i}\frac{\partial\psi_r}{\partial x^j}
\end{equation}
i, agrupant termes en $a_\nu$, obtenim el resultat.\qed
}




























\newpage
\section{Explicació del Sung-Jin Oh}
\begin{teo}\label{teo: SJO} Sigui $(M,g)$ una superfície, $N\ge\dim M+1$ i $u:M\to\mathbb R^N$ una encabiment estrictament curta, és a dir, tal que la longitud de cada vector en $M$ s'escurça (estrictament) sota $\nabla u$. Aleshores $u$ es pot aproximar uniformement per encabiments isomètriques $C^1$.
\end{teo}
{\color{blue} Haurem d'explicar què és una encabiment isomètrica, i mirar si cal que li canviem el nom}

Per exemple, l'homotècia $\mathbb S^2\to\varepsilon\mathbb S^2$ amb $\varepsilon\in(0,1)$ és una aplicació \textit{curta}. 
\begin{obs}
De fet, qualsevol encabiment $C^2$ isomètrica $u:\mathbb S^2\hookrightarrow\mathbb R^3$ ha de ser igual a la encabiment estàndard $\mathbb S^2 \hookrightarrow\set{ x\in\mathbb R^3 : |X| = 1 }$ fins translació i rotació. 
\end{obs}

El teorema \ref{teo: SJO} es demostra amb \textit{integració convexa}.

Sung-Jin Oh demostra aquí el Baby Nash theorem.


Sigui $D=\set{x\in\mathbb R^2 : |x|<1}$ el disc unitat, i $g = g_{ij}(x)$ una mètrica de $D$. Una aplicació $u:D\to\mathbb R^n$ és una \textit{immersió} {\color{blue} per ara direm encabiment als embeddings i immersions als \textit{immersions}} si $\nabla u(x)$ és injectiva per tot $x$. La mètrica en $D$ induïda per $u$ és de la forma {\color{blue} Haurem de recordar i controlar el que era la mètrica induïda}
\begin{equation*}
    \nabla u ^{\intercal}(x)\nabla u (x) = \begin{pmatrix}
    \nabla_1 u\nabla_1 u & \nabla_1 u\nabla_2 u\\
    \nabla_2 u\nabla_1 u & \nabla_2 u\nabla_2 u
    \end{pmatrix}
\end{equation*}
Diem que l'aplicació és \textit{isomètrica} {\color{blue} també estaria bé comentar isometries} si $\nabla u ^{\intercal}\nabla u = g$, i diem que és \textit{(estrictament) curta} si $\nabla u(x)^{\intercal} \nabla u(x) - g(x) \le 0$ per tot $x\in D$.
\begin{teo}\label{Baby Nash} [Baby Nash]
    Sigui $n\ge 4$ i $u:D\to\mathbb R^n$ una immersió estrictament curta. Per qualsevol $\varepsilon > 0$, existeix una immersió isomètrica $C^1$ $\tilde u:D\to\mathbb R^n$ tal que $\|u-\tilde u\|_{C^0(D)} < \varepsilon$.{\color{blue} Aquí cal motivar l'interès d'aquest resultat. Entenc que la idea és que partim d'una immersió que és estrictament curta i volem trobar una que sigui contínua i isomètrica. Vull mirar continuïtats.}
\end{teo}
\begin{obs}
    Aquest teorema necessita que la co-dimensió sigui com a mínim 2.
\end{obs}
La manera de demostrar aquest resultat és a través d'un mètode iteratiu amb passos altament oscil·lants.
Sigui $u_1 = u + U$ amb 
\begin{equation*}
    U=\sum_{I\in\mathcal I} U_I
\end{equation*}
Volem que cada component $U_I^j$ sigui complex, per tal que oscil·li com $e^{ix \cdot \xi}$, però que el resultat del sumatori sigui real. Així, imposem que per cada $I\in\mathcal I$ que existeixi $\overline I\in\mathcal I$ tal que 
\begin{equation*}
    U_{\overline{I}} = \overline{U}_I, \quad \overline{\overline{I}} = I.
\end{equation*}
Ara tenim un error mètric $h_1 = g - \nabla u_1 ^{\intercal}\nabla u_1$. {\color{blue} On entenem que l'error mètric és la diferència entre la mètrica i la mètrica induïda per la immersió? Té sentit, però cal veure per què només agafo el primer terme.}
\begin{equation*}
    h_1 = 
        \left( h-\sum_{I} \nabla \overline{U}_I ^{\intercal}\nabla U_I \right) 
        - \sum_{I}\left( \nabla u ^{\intercal}\nabla U_I + \nabla U_I ^{\intercal}\nabla u \right)
        - \sum_{I,J: J\not = \overline I} \nabla U_I ^{\intercal}\nabla U_J.
\end{equation*}
I anomenem els tres sumands, en ordre, $q_{\text{mèt}}$, $q_{\text{lin}}$ i $q_{\text{alt}}$.

Volem una correcció que oscil·li en una sola direcció $\xi\in\mathbb R^2$, $|\xi|=1$. Posem
\begin{equation*}
    U_I = W = \frac1\lambda a(x)\textbf{n}(x)e^{\lambda i x \cdot \xi},
\end{equation*}
amb $a:D\to\mathbb R$ i $\textbf{n}:D\to\mathbb C^n$ tal que $\textbf{n}\cdot \overline{\textbf{n}}=1$. Per tal que sigui real, definim també $\overline I\in\mathcal I$ tal que 
\begin{equation*}
    U_{\overline{I}} = \overline W = \frac1\lambda a(x)\overline{\textbf{n}}(x)e^{-\lambda i x \cdot \xi}.
\end{equation*}

Per eliminar el terme $q_{\text{mèt}}$, observem que
\begin{equation*}
    \begin{aligned}
    \nabla_j W &= i\xi_j a(x)\textbf{n}(x)e^{\lambda i x \cdot \xi} + \frac{1}{\lambda}\nabla_j (a(x)\textbf{n}(x))e^{\lambda i x \cdot \xi}\\
    &=i\xi_j a(x)\textbf{n}(x)e^{\lambda i x \cdot \xi} + O(\frac{1}{\lambda})
    \end{aligned}
\end{equation*}
{\color{blue} EXPLICAR PER QUÈ ÉS O(1/LAMBDA)!!! De fet, explicar d'on surt la lambda aquesta.}
I, per tant,
\begin{equation*}
    \begin{aligned}
    \nabla_i W^*(x) \nabla_jW(x)&= (-i\xi_ia(x)e^{-\lambda i x \cdot \xi})(i\xi_ja(x)e^{\lambda i x \cdot \xi})\overline{\textbf{n}}(x) \cdot\textbf{n}(x) + O(\frac{1}{\lambda})\\
    &= \xi_i\xi_j a(x)^2 + O(\frac{1}{\lambda})
    \end{aligned}
\end{equation*}
on definim $(\cdot)^* = (\overline{\cdot})^\intercal$. Així, l'oscil·lació és cancel·lada i en resulta un terme $a(x)^2\xi_i\xi_j$.
\begin{ex}
    {\color{blue} EXPLICAR MILLOR AQUEST EXEMPLE}
    Posem que per un cert $x\in D$, l'error $h$ és de la forma
    \begin{equation*}
        h(x) = a^2(x)\xi \otimes \xi + b^2(x)\xi' \otimes \xi' + c^2(x)\xi'' \otimes \xi''
    \end{equation*}
    aleshores, amb això fem desaparèixer el terme $\xi \otimes \xi$. Repetint-ho per $\xi' \otimes \xi'$ i $\xi'' \otimes \xi''$ aconseguim reduir l'error $h(x)$ a un terme $O(\frac{1}{\lambda})$.
\end{ex}
\begin{obs}
    {\color{blue} EXPLICAR AQUESTA OBSERVACIÓ}
    Aquest mètode requereix que $h$ sigui curta, ja que $\nabla_i W^*(x) \nabla_jW(x)$ és un terme no-negatiu. De fet, per tal que $h_1$ sigui curt, necessitem que $h$ sigui estrictament curt.
\end{obs}
Ara bé, els autovectors $\xi$ depenen d'$x$. Això es pot resoldre amb el següent lema.
\begin{lema}\label{lema:descomposicio_error_metric} (Descomposició de l'error mètric)
    Sigui $\mathcal P$ l'espai de totes les matrius definides positives. Existeix una successió $\xi^{(k)}$ de vectors unitaris en $\mathbb R^n$ i una successió $\Gamma_{(k)}\in C_c^\infty(\mathcal P; [0,\infty))$ tals que
    \begin{equation*}
        A_{ij} = \sum_k\Gamma^2_{k}(A)\xi_i^{(k)}\xi_j^{(k)}
    \end{equation*}
    i aquesta suma és \textit{localment finita}. És a dir, existeix $N\in\mathbb N$ tal que per tot $A\in\mathcal P$ com a màxim $N$ termes de $\Gamma_{(k)}$ són no-nuls.
\end{lema}
\begin{obs}
    La demostració d'aquest teorema no l'escrivim aquí explícitament. {\color{blue} ESTÀ AL SUNG-JIN OH.}
\end{obs}
Fins ara no ha calgut especificar el vector $\textbf{n}(x)\in\mathbb C^n$ per tal de minimitzar l'error mètric, més enllà que necessitem que sigui unitari. Veurem que el podem escollir de tal manera que els termes $q_{\text{lin}}$ i $q_{\text{alt}}$ desapareguin fins a terme $O(1/\lambda)$.
\begin{itemize}

    \item \textbf{Error de linearització.} Substituïm el terme amb $W$
    \begin{equation*}
         \nabla_i u ^{\intercal}\nabla_j W = i\xi_j a(x)e^{ix\cdot\xi}\nabla_i u\cdot\textbf{n}+O(1/\lambda)
    \end{equation*}
    i veiem que podem eliminar aquest component escollint un vector perpendicular a l'espai tangent de $u(x)$, $\textbf{n}(x)\perp \nabla_j u(x)$. Això es pot fer perquè l'espai té co-dimensió 1 ({\color{blue}REVISAR!!!}). Podem fer el mateix amb $\nabla_iW^{\intercal}\nabla_ju$ i obtenim
    \begin{equation*}
        \nabla_i u ^{\intercal}\nabla_j W + \nabla_iW^{\intercal}\nabla_ju = O(1/\lambda)
    \end{equation*}

    \item \textbf{Interferència altament oscil·lant.} De nou, substituïm el terme
    \begin{equation*}
        \nabla_iW^{\intercal}\nabla_jW = (-a^2(x)\xi_i\xi_je^{2ix\cdot\xi})\textbf{n}\cdot\textbf{n} + O(1/\lambda).
    \end{equation*}
    I ara només cal utilitzar que la encabiment té co-dimensió $\ge2$ per escollir un vector complex tal que $\textbf{n}\cdot\textbf{n} = 0$ {\color{blue}Com està definit aquest producte?}. Podem prendre, per exemple, 
    \begin{equation*}
        \textbf{n} = \frac{1}{i\sqrt2}\zeta(x) + \frac{1}{\sqrt2}\eta(x)
    \end{equation*}
    on $\zeta(x)$ i $\eta(x)$ són vectors reals unitaris ortogonals a l'espai tangent $T_{u(x)}u(D)$.
    \item \textbf{Forma final de la correcció.} Tot plegat, tenim una correcció de la forma
    \begin{equation*}
        W(x) = \frac{a(x)}{\lambda}\left( \sin(\lambda x \cdot \xi)\zeta(x) + \cos(\lambda x \cdot \xi)\eta(x) \right)
    \end{equation*}
    amb les següents propietats:
    \begin{itemize}
        \item[--] Norma $C^0$ petita {\color{blue} Explicar C-normes}: $$||W||_{C^0}\le C\frac{||a||_{C^0}}{\lambda}$$
        \item[--] Terme principal en $\nabla W$ 
        \begin{equation*}
            \begin{aligned}
                \nabla W = &a(x)\left( \cos(\lambda x \cdot \xi)\zeta(x) - \sin(\lambda x \cdot \xi)\eta(x) \right) \\
                &+ O_{||a||_{C^0}, ||\nabla a||_{C^0}, ||\nabla\zeta||_{C^0}, ||\nabla\eta||_{C^0}}(1/\lambda)
            \end{aligned}
        \end{equation*}
        \item[--] Error mètric petit: $$\nabla_i W^{\intercal}\nabla_j W(x) -a^2(x)\xi_i\xi_j = O(1/\lambda)$$
        \item[--] Error de linearització petit: $$\nabla_i u ^{\intercal}\nabla_j W + \nabla_iW^{\intercal}\nabla_ju = O(1/\lambda)$$
        \item[--] Error d'interferència petita: $$\nabla_i W ^{\intercal}\nabla_j W = O(1/\lambda)$$
    \end{itemize}
\end{itemize}
\begin{obs}
    {\color{blue} Aquesta derivada es pot entendre si l'escrius i fas els passos. Mirar si cal explicar-ho millor.}
    Una manera alternativa d'arribar a la forma general de la correcció és la següent. Definim 
    \begin{equation*}
        \begin{aligned}
        \gamma = (\gamma_1, \gamma_2) : &D\times \mathbb T\to \mathbb R^2\\
        & (x,t)\mapsto \gamma(x,t)
        \end{aligned}
    \end{equation*}
    on $\mathbb T = \mathbb R / 2\pi\mathbb Z$.
    Posant $\dot\gamma$ la derivada respecte de $t$, tenim que
    \begin{equation*}
        \nabla W ^{\intercal}(x) \nabla W(x) = \left( \dot\gamma_1^2(x, \lambda x\cdot\xi) + \dot\gamma_2^2(x, \lambda x\cdot\xi) \right)\xi\otimes\xi + O(1/\lambda).
    \end{equation*}
    De manera que per cada $x$ cal trobar $\gamma(x,\cdot)$ tal que 
    (1) $\dot\gamma_1^2 + \dot\gamma_2^2 = a^2$ i 
    (2) $t\mapsto \dot\gamma(x,t)$ sigui $2\pi$-periòdic i $\int\dot\gamma\text{d}t = 0$
    De manera que $t\mapsto\gamma(x,t)$ també ha de ser $2\pi$-periòdica i el seu origen ha de pertànyer al disc unitat tancat $\overline D$.
    {\color{blue} IMPORTANT Per a després, NASH ANOMENA STEP A CADA ADDICIÓ D'UNA CORRECCIÓ, que es carrega un terme a un error d'ordre $O(1/\lambda)$. }
\end{obs}
\begin{lema}[Lema d'iteració]\label{Lema_iteracio}
    Sigui $u:D\to\mathbb R^n$ una immersió suau estrictament curta, tal que $h:=g-\nabla u ^{\intercal}\nabla u$ obeeix
    \begin{equation}
        ||h||_{C^0} \le e_h
    \end{equation}
    per algun $e_h > 0$. Aleshores, per qualsevol $\varepsilon > 0$, existeix una immersió suau estrictament curta $u_{[1]} = u + U$, on
    \begin{equation}
        \begin{aligned}
        ||U||_{C^0(D)} &\le \varepsilon\\
        ||\nabla U||_{C^0(D)} &\le Ce_h^{1/2}
        \end{aligned}
    \end{equation}
    i $h_{[1]}:=g-\nabla u_{[1]}^{\intercal}\nabla u_{[1]}$ obeeix
    \begin{equation}
        ||h_{[1]}-h||_{C^0} \le \varepsilon.
    \end{equation}
\end{lema}
\textit{Prova.} Pel lema \ref{lema:descomposicio_error_metric}, tenim que $h$ es pot escriure com
\begin{equation*}
    h(x) = \sum_k \Gamma^2_{(k)}(h(x))\xi^{(k)}\otimes\xi^{(k)}
\end{equation*}
on per cada $h(x)$ hi ha com a molt $K$ termes no-nuls.

Per la compacitat d' $h(D)\subseteq\mathcal P$, existeix un nombre finit de sumands que són funcions no-nul·les{\color{blue} Non-vanishing, mirar la traducció}. Reanomenem aquests sumands d'aquesta manera:
\begin{equation*}
    \Gamma^2_{(1)}(h(x))\xi^{(1)}\otimes\xi^{(1)}, \Gamma^2_{(2)}(h(x))\xi^{(2)}\otimes\xi^{(2)}, \dots, \Gamma^2_{(N)}(h(x))\xi^{(N)}\otimes\xi^{(N)}
\end{equation*}
Prenent la traça, veiem que 
\begin{equation*}
    ||\Gamma_{(j)}(h)||_{C^0} \le ||h||_{C^0}^{1/2} \le e_h^{1/2}
\end{equation*}
{\color{blue} Mirar d'on surt això (Sembla Cauchy-Schwarz, però què passa amb la traça de h?)}
Ara podem fer $N$ correccions a $u$ de la mateixa manera que hem fet abans, en les direccions $\xi^{(1)}, \xi^{(2)}, \dots, \xi^{(N)}$, per cancel·lar aquests errors. En concret, per un $\delta>0$, definim de manera recursiva $u_j = u_{j-1}+(1-\delta)^{1/2}U_j$, amb $u_0 = u$ i 
\begin{equation*}
    U_j = \frac{\Gamma_{(j)}(h(x))}{\lambda_j}\left( \sin(\lambda_j x\cdot\xi^{(j)})\zeta_j(x) + \cos(\lambda_j x\cdot\xi^{(j)})\eta_j(x) \right)
\end{equation*}
per uns certs $\lambda_j$ i $\zeta_j, \eta_j:D\to\mathbb R^n$ unitaris.

Prenem $\delta > 0$ per tal d'assegurar curtedat estricta {\color{blue} no sé com es diu shortness la veritat}. De fet, fixem $0<\delta<\frac{\varepsilon}{2e_h^{1/2}}$ per tal que $h\ge\delta I$. {\color{blue} uiuiui això mirar-ho bé}

Escollint $\lambda_j$ prou gran, tenim
\begin{itemize}
    \item[--]
    \begin{equation}
        ||U_j||_{C^0} \ll \varepsilon
    \end{equation}
    \item[--]
    \begin{equation}
        \nabla U_j = \Gamma_{(j)}(h)\xi^{(j)}(\cos(\lambda_j x\cdot\xi^{(j)})\zeta - \sin(\lambda_j x\cdot\xi^{(j)})\eta) + \text{err}_j,\quad ||\text{err}_j||_{C^0} \ll \varepsilon
    \end{equation}
    \item[--]
    \begin{equation}
        h_j=h_{j-1}-(1-\delta)\Gamma^2_{(k)}(h)\xi^{(j)}\xi^{(j)} + \text{err}_j', \quad ||\text{err}_j'||_{C^0} \ll \delta^2
    \end{equation}
    {\color{blue} Les dues primeres són fàcils d'entendre, però la tercera l'hem de revisar.}
\end{itemize}
On $h_j=g-\nabla u_j ^{\intercal}\nabla u_j$. 

Per tal de concloure la prova, verifiquem que $U=U_1+\dots+U_N$ i $u_{[1]}=u_N=u+U$ satisfan les propietats desitjades.

\begin{itemize}
    \item És fàcil veure que $||U_j|| \ll \varepsilon$ implica $||U||_{C^0(D)} \ll \varepsilon$.
    \item A més, de $\nabla U_j = \Gamma_{(j)}(h)\xi^{(j)}(\cos(\lambda_j x\cdot\xi^{(j)})\zeta - \sin(\lambda_j x\cdot\xi^{(j)})\eta) + \text{err}_j$ i $||\Gamma_{(j)}(h)||_{C^0} \le e_h^{1/2}$ tenim que $||\nabla U||_{C^0(D)} \le Ke_h^{1/2} + \sum_{j=1}^N ||\text{err}_j||_{C^0} \le 2Ke_h^{1/2}$ si es prenen les constants adequades. 
    \item Finalment, sumant els termes $h_j$ obtenim 
    \begin{equation*}
        h_N = h-(1-\delta)\sum_{j=1}^N \Gamma^2_{(j)}(h)\xi^{(j)}\xi^{(j)} + \sum_{j=1}^N \text{err}'_j = \delta h + \sum_{j=1}^N \text{err}'_j
    \end{equation*}
    i imposant que $u_{[1]} = u_N$ sigui estrictament curta, $h_{[1]}=h_N \ge \delta^2 I$, obtenim el resultat.
\end{itemize}
\qed

Ara podem iterar diverses vegades per concloure la prova del teorema \ref{Baby Nash}.

\textit{Prova del teorema \ref{Baby Nash}.} Sigui $e_{h,[k]}>0$ una successió tal que
$$\sum_{k}e_{h,[k]}\le \epsilon,\quad\sum_{k}e_{h,[k]}^{1/2}<\infty.$$ 
Pel lema \ref{Lema_iteracio}, obtenim una successió d'aplicacions suaus estrictament curtes $u_{[k]}$ tal que $u_{[0]}=u$ i
\begin{equation*}
    \begin{aligned}
    ||g-\nabla u_{[k]}^\intercal\nabla u_{[k]}||_{C^0} &\le e_{h,[k]}\\
    ||\nabla u_{[k+1]}-\nabla u_{[k]}||_{C^0} &\le Ce^{1/2}_{h,[k]}\\
    ||u_{[k+1]}-u_{[k]}||_{C^0} &\le e_{h,[k+1]},
    \end{aligned}
\end{equation*}
demostrant el teorema.\qed

{\color{blue} revisar això últim perquè just estava parlant amb la marina}
\subsection{Extensions}
\subsubsection{Extensió a encabiments de varietats}
Per estendre el teorema \ref{Baby Nash} a immersions a superfícies generals, només cal reduir a cartes coordenades. Per estendre'l a encabiments usem que, per la compacitat d'$M$, podem trobar $\varepsilon>0$ tal que 
$$\inf_{x,y} \text{dist}(u(x), u(y))\ge\varepsilon.$$ Ara només cal dur a terme la construcció en un entorn de $0.01\varepsilon$.{\color{blue} entendre millor això últim perquè és bastant random}
\subsubsection{Refinament de Kuiper: encabiment de codimensió 1}
Modificant la forma de la correcció, podem aconseguir la mateixa construcció amb només co-dimensió 1. Sigui $\eta:D\to\mathbb R^{3}$ el camp vectorial unitari en $u(D)$, i sigui
$$\zeta = \nabla u (\nabla u^\intercal \nabla u)^{-1}\xi.$$
Prenem 
$$U = \frac1\lambda \left( \gamma_{1}(x, \lambda x \cdot \xi)\tilde{\zeta}(x) + \gamma_{2}(x, \lambda x \cdot \xi)\tilde{\eta}(x) \right)$$
on 
$$\tilde{\zeta} = \frac{\zeta}{|\zeta|^2}, \quad \tilde{\eta} = \frac{\eta}{|\zeta|},$$
i $u_1 = u + U$. Això porta a 
{\color{blue} paper i boli}
$$\nabla u_1^\intercal \nabla u_1 = \nabla u^\intercal \nabla u +\frac{1}{|\zeta|^2}\left( 2\dot\gamma_{1} + \dot\gamma_1^2 + \dot\gamma_{2}^2 \right) \xi \otimes \xi + O(1/\lambda).$$
De manera que per cada $x$ i $a=a(x)\in\mathbb R$ volem que $\gamma$ sigui tal que
\begin{itemize}
    \item {\color{blue} posar això amb la cosa aquella de (1) i (2)}
    \item $(1+\dot\gamma_1)^2+\dot\gamma_2^2=|\zeta|^2a^2+1$,
    \item $t \mapsto \dot\gamma(x,t)$ és $2\pi$-periòdica i $\int\dot\gamma\textrm{d}t=0$
\end{itemize}
i tal que $|\dot\gamma|\le C|a|$. Això és possible perquè l'envolupant convexa de $\set{(x,y):(1+x)^2+y^2 = |\zeta|^2a^2+1}$ conté el $0$. 




\newpage